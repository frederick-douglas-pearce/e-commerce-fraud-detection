{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad64f69-0f35-4c18-b252-8414bb787f08",
   "metadata": {},
   "source": [
    "# E-Commerce Fraud Detection\n",
    "\n",
    "This project models E-Commerce transaction data to identify fraudelent activity, based on this [Kaggle Dataset](https://www.kaggle.com/datasets/umuttuygurr/e-commerce-fraud-detection-dataset). The dataset is synthetic, but very realistic, as it is modeled after real-life fraudulent activity observed in 2024, with scenarios such as\n",
    "- Cards tested with $1 purchases at midnight\n",
    "- Transactions that shipped “gaming accessories” 5,000 km away\n",
    "- Promo codes being reused from freshly created accounts.\n",
    "\n",
    "I decided to focus on this dataset as it is the most complete, realistic data on transaction fraud that I could find. Other fraud datasets that weren't synthetic had to obfuscate the meaning of features and their values for privacy reasons, using techniques like PCA, so features had meaningless names like V1, V2, etc.\n",
    "\n",
    "Here is a list of the columns in the dataset with brief descriptions:\n",
    "\n",
    "- `transaction_id`: Unique transaction identifier\n",
    "- `user_id`: User identifier (each user 40–60 transactions)\n",
    "- `account_age_days`: Age of user account in days\n",
    "- `total_transactions_user`: Number of transactions per user\n",
    "- `avg_amount_user`: User’s mean transaction amount\n",
    "- `amount`: Transaction amount (USD)\n",
    "- `country`: User’s country\n",
    "- `bin_country`: Country of the card-issuing bank\n",
    "- `channel`: “web” or “app”\n",
    "- `merchant_category`: Type of purchase: electronics, fashion, grocery, gaming, travel\n",
    "- `promo_used`: whether a discount/promo was used\n",
    "- `avs_flag`: Address Verification result, a mismatch in the billing address provided by a customer and the one on file with their card issuer.\n",
    "- `cvv_result`: CVV code match result, indicates if 3 digit code on back of card provided during an online transaction matched the card issuer's records\n",
    "- `three_ds_flag`: 3D Secure enabled, so if a transaction is flagged, it prompts the customer to complete an extra verification step, such as a one-time code sent to your phone, a password, or biometric login\n",
    "- `transaction_time`: Transaction timestamp (UTC)\n",
    "- `shipping_distance_km`: Distance between billing and shipping addresses\n",
    "- `is_fraud`: Target label (1 = fraud, 0 = normal)\n",
    "\n",
    "## Setup\n",
    "### Define parameters\n",
    "The input/output parameters are defined in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98a09af0-b9e7-4f1c-b6b4-8eeca224303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data input parameters\n",
    "kaggle_source = \"umuttuygurr/e-commerce-fraud-detection-dataset\"\n",
    "data_dir = \"./data\"\n",
    "csv_file = \"transactions.csv\"\n",
    "# Column definitions\n",
    "target_col = \"is_fraud\"\n",
    "id_cols = ['transaction_id', 'user_id']\n",
    "date_col = 'transaction_time'\n",
    "# Validation/Test split ratios\n",
    "val_ratio = .2\n",
    "test_ratio = .2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a434d-589e-4ddd-bbe2-84ac8e4fd12a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "uo1vve11ske",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mutual_info_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4f016-cf81-47bd-8f1e-862591e2f911",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "54mtlgnwh8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data_csv(kaggle_source, data_dir, csv_file):\n",
    "    \"\"\"Download csv file from kaggle_source. Requires install of kaggle python\n",
    "    package to use the Kaggle API and Kaggle API credentials set up in\n",
    "    `~/.kaggle/kaggle.json`. Creates data directory, data_dir, if it doesn't\n",
    "    exist. csv_file is the name of the downloaded file.\n",
    "    \"\"\"\n",
    "    Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "    if not os.path.exists(f\"{data_dir}/{csv_file}\"):\n",
    "        print(f\"\\nDownloading dataset from Kaggle...\")\n",
    "        !kaggle datasets download -d {kaggle_source} -p {data_dir} --unzip\n",
    "        print(\"Download complete!\")\n",
    "    else:\n",
    "        print(f\"\\nDataset already exists at {data_dir}/{csv_file}\")\n",
    "\n",
    "def load_data(data_dir, csv_file, verbose=True):\n",
    "    df = pd.read_csv(\n",
    "        f\"{data_dir}/{csv_file}\",\n",
    "        low_memory=False  # Read entire file to infer dtypes properly\n",
    "    )\n",
    "    if verbose:\n",
    "        print(f\"\\nDataset Shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        print(f\"\\nMemory Usage:\\n{df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    return df\n",
    "\n",
    "def analyze_target_stats(df, target_col):\n",
    "    # Target distribution\n",
    "    target_dist = df[target_col].value_counts(normalize=True)\n",
    "    print(\"\\nTarget Distribution (%):\")\n",
    "    print(target_dist * 100)\n",
    "    # Check class imbalance\n",
    "    target_vals = target_dist.values\n",
    "    target_ratio = target_vals[0] / target_vals[1]\n",
    "    if target_ratio > 10:\n",
    "        print(f\"\\nWarning: Large class imbalance ({target_ratio:.1f}) detected!\")\n",
    "    else:\n",
    "        print(f\"\\nClass imbalance = {target_ratio:.1f}\")\n",
    "\n",
    "def analyze_feature_stats(df, id_cols, target_col):\n",
    "    # Summary for categorical/object columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if len(categorical_cols) > 0:\n",
    "        print(\"Categorical Columns Summary:\")\n",
    "        for col in categorical_cols:\n",
    "            print(f\"\\n{col}:\")\n",
    "            print(f\"  Unique values: {df[col].nunique()}\")\n",
    "            print(f\"  Top 5 values:\\n{df[col].value_counts().head()}\")\n",
    "\n",
    "    # Statistical summary for numerical columns\n",
    "    numeric_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "    numeric_cols = [nc for nc in numeric_cols if nc not in id_cols and nc != target_col]\n",
    "    print()\n",
    "    display(df[numeric_cols].describe())\n",
    "        \n",
    "def split_train_val_test(df, val_ratio=.2, test_ratio=.2, stratify=None, r_seed=1, verbose=False):\n",
    "    \"\"\"Use the train_test_split function from sklearn to split input dataframe\n",
    "    into randomly shuffled train, validation, and test datasets with the\n",
    "    validation dataset containing val_ratio of the input data and the test\n",
    "    dataset containing test_ratio of the input data. Stratify, if provided, is \n",
    "    the name of the column in df to use when stratifying the splits.\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    # Generate test dataset\n",
    "    strat_col = stratify\n",
    "    if stratify:\n",
    "        strat_col = df[stratify]\n",
    "    full_train_df, test_df = train_test_split(df, test_size=test_ratio, stratify=strat_col, random_state=r_seed)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "    # Generate train, validation, and test splits\n",
    "    val_ft_ratio = val_ratio / (1 - test_ratio)\n",
    "    if stratify:\n",
    "        strat_col = full_train_df[stratify]\n",
    "    train_df, val_df = train_test_split(full_train_df, test_size=val_ft_ratio, stratify=strat_col, random_state=r_seed)\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    val_df = val_df.reset_index(drop=True)\n",
    "    if verbose:\n",
    "        print(f\"All rows in the original dataframe are contained within the training, validation, or test datasets: {len(train_df) + len(val_df) + len(test_df) == len(df)}\")\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "def calculate_mi_scores(df, categorical_features, target_col):\n",
    "    \"\"\"\n",
    "    Calculate mutual information scores for categorical and ordinal features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    categorical_features : list\n",
    "        List of categorical feature column names\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with features and their MI scores, sorted by score descending\n",
    "    \"\"\"\n",
    "    mi_scores = []\n",
    "    \n",
    "    for feature in categorical_features:\n",
    "        score = mutual_info_score(df[feature], df[target_col])\n",
    "        mi_scores.append({'feature': feature, 'mi_score': score})\n",
    "    \n",
    "    mi_df = pd.DataFrame(mi_scores).sort_values('mi_score', ascending=False).reset_index(drop=True)\n",
    "    return mi_df\n",
    "\n",
    "\n",
    "def calculate_numeric_correlations(df, numeric_features, target_col):\n",
    "    \"\"\"\n",
    "    Calculate Pearson correlations for numeric features with target.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    numeric_features : list\n",
    "        List of numeric feature column names\n",
    "    target_col : str\n",
    "        Name of target column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with features and their correlation with target, sorted by absolute value descending\n",
    "    \"\"\"\n",
    "    correlations = []\n",
    "    \n",
    "    for feature in numeric_features:\n",
    "        corr = df[feature].corr(df[target_col])\n",
    "        correlations.append({'feature': feature, 'correlation': corr, 'abs_correlation': abs(corr)})\n",
    "    \n",
    "    corr_df = pd.DataFrame(correlations).sort_values('abs_correlation', ascending=False).reset_index(drop=True)\n",
    "    return corr_df[['feature', 'correlation']]\n",
    "\n",
    "\n",
    "def calculate_vif(df, numeric_features):\n",
    "    \"\"\"\n",
    "    Calculate Variance Inflation Factor for numeric features.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe\n",
    "    numeric_features : list\n",
    "        List of numeric feature column names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : DataFrame with features and their VIF values, sorted by VIF descending\n",
    "    \"\"\"\n",
    "    # Create subset with only numeric features\n",
    "    X = df[numeric_features].values\n",
    "    \n",
    "    vif_data = []\n",
    "    for i, feature in enumerate(numeric_features):\n",
    "        vif = variance_inflation_factor(X, i)\n",
    "        vif_data.append({'feature': feature, 'VIF': vif})\n",
    "    \n",
    "    vif_df = pd.DataFrame(vif_data).sort_values('VIF', ascending=False).reset_index(drop=True)\n",
    "    return vif_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d3e4f-c850-4597-99b2-1131a4ab89a0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "revrvtxo5o8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nDataset already exists at ./data/transactions.csv\n",
      "\n",
      "Dataset Shape: 299695 rows, 17 columns\n",
      "\n",
      "Memory Usage:\n",
      "107.29 MB\n"
     ]
    }
   ],
   "source": [
    "download_data_csv(kaggle_source, data_dir, csv_file)\n",
    "input_df = load_data(data_dir, csv_file, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a88cf89a-7b52-4ce8-86ba-074e98444e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>total_transactions_user</th>\n",
       "      <th>avg_amount_user</th>\n",
       "      <th>amount</th>\n",
       "      <th>country</th>\n",
       "      <th>bin_country</th>\n",
       "      <th>channel</th>\n",
       "      <th>merchant_category</th>\n",
       "      <th>promo_used</th>\n",
       "      <th>avs_match</th>\n",
       "      <th>cvv_result</th>\n",
       "      <th>three_ds_flag</th>\n",
       "      <th>transaction_time</th>\n",
       "      <th>shipping_distance_km</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>147.93</td>\n",
       "      <td>84.75</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>web</td>\n",
       "      <td>travel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-06T04:09:39Z</td>\n",
       "      <td>370.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>147.93</td>\n",
       "      <td>107.90</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>web</td>\n",
       "      <td>travel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-01-09T20:13:47Z</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>147.93</td>\n",
       "      <td>92.36</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>app</td>\n",
       "      <td>travel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-12T06:20:11Z</td>\n",
       "      <td>164.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>147.93</td>\n",
       "      <td>112.47</td>\n",
       "      <td>FR</td>\n",
       "      <td>FR</td>\n",
       "      <td>web</td>\n",
       "      <td>fashion</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-15T17:00:04Z</td>\n",
       "      <td>397.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>47</td>\n",
       "      <td>147.93</td>\n",
       "      <td>132.91</td>\n",
       "      <td>FR</td>\n",
       "      <td>US</td>\n",
       "      <td>web</td>\n",
       "      <td>electronics</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-01-17T01:27:31Z</td>\n",
       "      <td>935.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  user_id  account_age_days  total_transactions_user  \\\n",
       "0               1        1               141                       47   \n",
       "1               2        1               141                       47   \n",
       "2               3        1               141                       47   \n",
       "3               4        1               141                       47   \n",
       "4               5        1               141                       47   \n",
       "\n",
       "   avg_amount_user  amount country bin_country channel merchant_category  \\\n",
       "0           147.93   84.75      FR          FR     web            travel   \n",
       "1           147.93  107.90      FR          FR     web            travel   \n",
       "2           147.93   92.36      FR          FR     app            travel   \n",
       "3           147.93  112.47      FR          FR     web           fashion   \n",
       "4           147.93  132.91      FR          US     web       electronics   \n",
       "\n",
       "   promo_used  avs_match  cvv_result  three_ds_flag      transaction_time  \\\n",
       "0           0          1           1              1  2024-01-06T04:09:39Z   \n",
       "1           0          0           0              0  2024-01-09T20:13:47Z   \n",
       "2           1          1           1              1  2024-01-12T06:20:11Z   \n",
       "3           0          1           1              1  2024-01-15T17:00:04Z   \n",
       "4           0          1           1              1  2024-01-17T01:27:31Z   \n",
       "\n",
       "   shipping_distance_km  is_fraud  \n",
       "0                370.95         0  \n",
       "1                149.62         0  \n",
       "2                164.08         0  \n",
       "3                397.40         0  \n",
       "4                935.28         0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "553ced16-83ae-461b-938b-f21a14af21f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 299695 entries, 0 to 299694\n",
      "Data columns (total 17 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   transaction_id           299695 non-null  int64  \n",
      " 1   user_id                  299695 non-null  int64  \n",
      " 2   account_age_days         299695 non-null  int64  \n",
      " 3   total_transactions_user  299695 non-null  int64  \n",
      " 4   avg_amount_user          299695 non-null  float64\n",
      " 5   amount                   299695 non-null  float64\n",
      " 6   country                  299695 non-null  object \n",
      " 7   bin_country              299695 non-null  object \n",
      " 8   channel                  299695 non-null  object \n",
      " 9   merchant_category        299695 non-null  object \n",
      " 10  promo_used               299695 non-null  int64  \n",
      " 11  avs_match                299695 non-null  int64  \n",
      " 12  cvv_result               299695 non-null  int64  \n",
      " 13  three_ds_flag            299695 non-null  int64  \n",
      " 14  transaction_time         299695 non-null  object \n",
      " 15  shipping_distance_km     299695 non-null  float64\n",
      " 16  is_fraud                 299695 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(5)\n",
      "memory usage: 38.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# No null values\n",
    "input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a07c5-f027-4b3b-b313-67e969143998",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Verify table grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f70f0951-7580-4b27-98e8-d301addb87ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every row is uniquely defined by transaction and user id columns: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Every row is uniquely defined by transaction and user id columns: {len(input_df)==len(input_df.drop_duplicates(subset=id_cols))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba466b7-3e7f-4f93-b743-9340becc68cc",
   "metadata": {},
   "source": [
    "### Target class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "qzjmrwuu47s",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target Distribution (%):\n",
      "is_fraud\n",
      "0    97.793757\n",
      "1     2.206243\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Warning: Large class imbalance (44.3) detected!\n"
     ]
    }
   ],
   "source": [
    "analyze_target_stats(input_df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31970e7d-0e36-4592-ad2e-297ee774f7ad",
   "metadata": {},
   "source": [
    "### Convert date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11e04f33-2ed8-4081-abd5-44f4ecdbca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df[date_col] = pd.to_datetime(input_df[date_col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6jfqm2m6xl2",
   "metadata": {},
   "source": [
    "### Feature stats\n",
    "Examine the distribution of categorical features and compute summary statistics for numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "mue0cr826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Columns Summary:\n",
      "\n",
      "country:\n",
      "  Unique values: 10\n",
      "  Top 5 values:\n",
      "country\n",
      "US    32430\n",
      "GB    30602\n",
      "FR    30343\n",
      "NL    30220\n",
      "TR    30074\n",
      "Name: count, dtype: int64\n",
      "\n",
      "bin_country:\n",
      "  Unique values: 10\n",
      "  Top 5 values:\n",
      "bin_country\n",
      "US    32295\n",
      "GB    30563\n",
      "FR    30261\n",
      "NL    30256\n",
      "TR    29972\n",
      "Name: count, dtype: int64\n",
      "\n",
      "channel:\n",
      "  Unique values: 2\n",
      "  Top 5 values:\n",
      "channel\n",
      "web    152226\n",
      "app    147469\n",
      "Name: count, dtype: int64\n",
      "\n",
      "merchant_category:\n",
      "  Unique values: 5\n",
      "  Top 5 values:\n",
      "merchant_category\n",
      "electronics    60220\n",
      "travel         59922\n",
      "grocery        59913\n",
      "gaming         59839\n",
      "fashion        59801\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>total_transactions_user</th>\n",
       "      <th>avg_amount_user</th>\n",
       "      <th>amount</th>\n",
       "      <th>promo_used</th>\n",
       "      <th>avs_match</th>\n",
       "      <th>cvv_result</th>\n",
       "      <th>three_ds_flag</th>\n",
       "      <th>shipping_distance_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "      <td>299695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>973.397871</td>\n",
       "      <td>50.673321</td>\n",
       "      <td>148.142973</td>\n",
       "      <td>177.165279</td>\n",
       "      <td>0.153640</td>\n",
       "      <td>0.837999</td>\n",
       "      <td>0.872110</td>\n",
       "      <td>0.784588</td>\n",
       "      <td>357.049028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>525.241409</td>\n",
       "      <td>5.976391</td>\n",
       "      <td>200.364624</td>\n",
       "      <td>306.926507</td>\n",
       "      <td>0.360603</td>\n",
       "      <td>0.368453</td>\n",
       "      <td>0.333968</td>\n",
       "      <td>0.411109</td>\n",
       "      <td>427.672074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>516.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>46.190000</td>\n",
       "      <td>42.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>136.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>975.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>90.130000</td>\n",
       "      <td>89.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>273.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1425.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>173.450000</td>\n",
       "      <td>191.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>409.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1890.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>4565.290000</td>\n",
       "      <td>16994.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3748.560000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       account_age_days  total_transactions_user  avg_amount_user  \\\n",
       "count     299695.000000            299695.000000    299695.000000   \n",
       "mean         973.397871                50.673321       148.142973   \n",
       "std          525.241409                 5.976391       200.364624   \n",
       "min            1.000000                40.000000         3.520000   \n",
       "25%          516.000000                46.000000        46.190000   \n",
       "50%          975.000000                51.000000        90.130000   \n",
       "75%         1425.000000                56.000000       173.450000   \n",
       "max         1890.000000                60.000000      4565.290000   \n",
       "\n",
       "              amount     promo_used      avs_match     cvv_result  \\\n",
       "count  299695.000000  299695.000000  299695.000000  299695.000000   \n",
       "mean      177.165279       0.153640       0.837999       0.872110   \n",
       "std       306.926507       0.360603       0.368453       0.333968   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%        42.100000       0.000000       1.000000       1.000000   \n",
       "50%        89.990000       0.000000       1.000000       1.000000   \n",
       "75%       191.110000       0.000000       1.000000       1.000000   \n",
       "max     16994.740000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       three_ds_flag  shipping_distance_km  \n",
       "count  299695.000000         299695.000000  \n",
       "mean        0.784588            357.049028  \n",
       "std         0.411109            427.672074  \n",
       "min         0.000000              0.000000  \n",
       "25%         1.000000            136.600000  \n",
       "50%         1.000000            273.020000  \n",
       "75%         1.000000            409.180000  \n",
       "max         1.000000           3748.560000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analyze_feature_stats(input_df, id_cols, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzbb1mqfv5j",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "41f0a139-73b3-492c-be55-88998a854f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transaction_id', 'user_id']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, val_df, test_df = split_train_val_test(pp_df, val_ratio=val_ratio, test_ratio=test_ratio, stratify=target_col, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654355-530c-4fad-bfef-ec877abe6e8c",
   "metadata": {},
   "source": [
    "## EDA\n",
    "### Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ccde8d-8957-4132-8fec-02a63d4677b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fac1e40c-bf3e-4131-ae31-adec008eb55e",
   "metadata": {},
   "source": [
    "### Numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf99b4-a53b-4a6e-992f-624923fe52ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "467d8a1f-40b9-405c-8e5f-64946117560e",
   "metadata": {},
   "source": [
    "#### Multicollinearity Detection (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6588c-bd29-4b59-8f3f-fa5b89c422f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27ec4922-9c2e-42a4-bac4-1eeab5a93dca",
   "metadata": {},
   "source": [
    "#### Bivariate Analysis: Features vs. Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1bf71-0a74-41b2-aebb-f75163feb545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1274e103-be4b-489f-9862-072ee8495fa5",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "#### Fraud Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec06196-7c0d-48b7-b8d8-3bc0d5160aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fec69343-8e91-4c4b-866b-ed7de8d08727",
   "metadata": {},
   "source": [
    "### Feature Selection Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8153d0a-ad4a-4076-8ef6-38c3078b79e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e18bebf-b405-40b4-9288-0d3084ce8924",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00040450-5cd1-4145-adf2-275dff681879",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
