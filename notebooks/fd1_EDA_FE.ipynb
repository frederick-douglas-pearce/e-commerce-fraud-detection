{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad64f69-0f35-4c18-b252-8414bb787f08",
   "metadata": {},
   "source": [
    "# E-Commerce Fraud Detection\n",
    "\n",
    "This project models E-Commerce transaction data to identify fraudelent activity, based on this [Kaggle Dataset](https://www.kaggle.com/datasets/umuttuygurr/e-commerce-fraud-detection-dataset). The dataset is synthetic, but very realistic, as it is modeled after real-life fraudulent activity observed in 2024, with scenarios such as\n",
    "- Cards tested with $1 purchases at midnight\n",
    "- Transactions that shipped ‚Äúgaming accessories‚Äù 5,000 km away\n",
    "- Promo codes being reused from freshly created accounts.\n",
    "\n",
    "I decided to focus on this dataset as it is the most complete, realistic data on transaction fraud that I could find. Other fraud datasets that weren't synthetic had to obfuscate the meaning of features and their values for privacy reasons, using techniques like PCA, so features had meaningless names like V1, V2, etc.\n",
    "\n",
    "Here is a list of the columns in the dataset with brief descriptions:\n",
    "\n",
    "- `transaction_id`: Unique transaction identifier\n",
    "- `user_id`: User identifier (each user 40‚Äì60 transactions)\n",
    "- `account_age_days`: Age of user account in days\n",
    "- `total_transactions_user`: Number of transactions per user\n",
    "- `avg_amount_user`: User‚Äôs mean transaction amount\n",
    "- `amount`: Transaction amount (USD)\n",
    "- `country`: User‚Äôs country\n",
    "- `bin_country`: Country of the card-issuing bank\n",
    "- `channel`: ‚Äúweb‚Äù or ‚Äúapp‚Äù\n",
    "- `merchant_category`: Type of purchase: electronics, fashion, grocery, gaming, travel\n",
    "- `promo_used`: whether a discount/promo was used\n",
    "- `avs_flag`: Address Verification result, a mismatch in the billing address provided by a customer and the one on file with their card issuer.\n",
    "- `cvv_result`: CVV code match result, indicates if 3 digit code on back of card provided during an online transaction matched the card issuer's records\n",
    "- `three_ds_flag`: 3D Secure enabled, so if a transaction is flagged, it prompts the customer to complete an extra verification step, such as a one-time code sent to your phone, a password, or biometric login\n",
    "- `transaction_time`: Transaction timestamp (UTC)\n",
    "- `shipping_distance_km`: Distance between billing and shipping addresses\n",
    "- `is_fraud`: Target label (1 = fraud, 0 = normal)\n",
    "\n",
    "## Setup\n",
    "### Define parameters\n",
    "The input/output parameters are defined in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a09af0-b9e7-4f1c-b6b4-8eeca224303e",
   "metadata": {},
   "outputs": [],
   "source": "# Data input parameters\nkaggle_source = \"umuttuygurr/e-commerce-fraud-detection-dataset\"\ndata_dir = \"../data\"  # Relative to notebooks/ folder\ncsv_file = \"transactions.csv\"\n# Column definitions\ntarget_col = \"is_fraud\"\nid_cols = ['transaction_id', 'user_id']\ndate_feature = 'transaction_time'\n# Define categorical features (including binary flags)\ncategorical_features = ['country', 'bin_country', 'channel', 'merchant_category', \n                       'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag']\n# Define numeric features (continuous/count variables only)\nnumeric_features = ['account_age_days', 'total_transactions_user', 'avg_amount_user', \n                   'amount', 'shipping_distance_km']\n# Validation/Test split ratios\nval_ratio = .2\ntest_ratio = .2\n\n# Prepend this string to final answers so they print as bold text\nBOLD = \"\\033[1m\""
  },
  {
   "cell_type": "markdown",
   "id": "379a434d-589e-4ddd-bbe2-84ac8e4fd12a",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uo1vve11ske",
   "metadata": {},
   "outputs": [],
   "source": "# Add project root to path for imports (needed when running from notebooks/ folder)\nimport sys\nfrom pathlib import Path\nproject_root = Path.cwd().parent\nif str(project_root) not in sys.path:\n    sys.path.insert(0, str(project_root))\n\n# Import extracted EDA utilities\nfrom src.fd1_nb.data_utils import (\n    download_data_csv, load_data, split_train_val_test, analyze_target_stats,\n    analyze_feature_stats, plot_target_distribution\n)\nfrom src.fd1_nb.eda_utils import (\n    calculate_mi_scores, calculate_numeric_correlations, calculate_vif,\n    plot_numeric_distributions, analyze_vif, analyze_correlations,\n    plot_box_plots, analyze_temporal_patterns, analyze_categorical_fraud_rates,\n    plot_categorical_fraud_rates, analyze_mutual_information\n)\nfrom src.fd1_nb.feature_engineering import (\n    convert_utc_to_local_time, create_temporal_features,\n    create_interaction_features, create_percentile_based_features\n)\n\n# Standard library imports (still used in notebook)\nimport pandas as pd\n\n# Utilities for feature configuration\nfrom src.deployment.preprocessing import FeatureConfig"
  },
  {
   "cell_type": "markdown",
   "id": "p3pm78g51c",
   "metadata": {},
   "source": [
    "### Define feature engineering functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ze9lfqqazi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ FEATURE ENGINEERING FUNCTIONS ============\n",
    "\n",
    "def get_country_timezone_mapping():\n",
    "    \"\"\"Create mapping of country codes to capital city timezones.\"\"\"\n",
    "    return {\n",
    "        'US': 'America/New_York',      # Washington D.C.\n",
    "        'GB': 'Europe/London',          # London\n",
    "        'FR': 'Europe/Paris',           # Paris\n",
    "        'DE': 'Europe/Berlin',          # Berlin\n",
    "        'IT': 'Europe/Rome',            # Rome\n",
    "        'ES': 'Europe/Madrid',          # Madrid\n",
    "        'NL': 'Europe/Amsterdam',       # Amsterdam\n",
    "        'PL': 'Europe/Warsaw',          # Warsaw\n",
    "        'RO': 'Europe/Bucharest',       # Bucharest\n",
    "        'TR': 'Europe/Istanbul'         # Istanbul\n",
    "    }\n",
    "\n",
    "def create_amount_features(df):\n",
    "    \"\"\"Create transaction amount-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Amount deviation from user's average\n",
    "    df['amount_deviation'] = (df['amount'] - df['avg_amount_user']).abs()\n",
    "    \n",
    "    # Amount ratio compared to user's average (handle division by zero)\n",
    "    df['amount_vs_avg_ratio'] = df['amount'] / df['avg_amount_user'].replace(0, 1)\n",
    "    \n",
    "    # Micro transactions (potential card testing)\n",
    "    df['is_micro_transaction'] = (df['amount'] <= 5).astype(int)\n",
    "    \n",
    "    # Large transactions\n",
    "    df['is_large_transaction'] = (df['amount'] >= df['amount'].quantile(0.95)).astype(int)\n",
    "    \n",
    "    features = ['amount_deviation', 'amount_vs_avg_ratio', 'is_micro_transaction', 'is_large_transaction']\n",
    "    return df, features\n",
    "\n",
    "def create_user_behavior_features(df):\n",
    "    \"\"\"Create user behavior-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Transaction velocity (transactions per day of account age)\n",
    "    df['transaction_velocity'] = df['total_transactions_user'] / df['account_age_days'].replace(0, 1)\n",
    "    \n",
    "    # New account flag (less than 30 days)\n",
    "    df['is_new_account'] = (df['account_age_days'] <= 30).astype(int)\n",
    "    \n",
    "    # High frequency user\n",
    "    df['is_high_frequency_user'] = (df['total_transactions_user'] >= df['total_transactions_user'].quantile(0.75)).astype(int)\n",
    "    \n",
    "    features = ['transaction_velocity', 'is_new_account', 'is_high_frequency_user']\n",
    "    return df, features\n",
    "\n",
    "def create_geographic_features(df, risk_distance_quantile=0.75):\n",
    "    \"\"\"Create geographic-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Country mismatch (user country != card issuing country)\n",
    "    df['country_mismatch'] = (df['country'] != df['bin_country']).astype(int)\n",
    "    \n",
    "    # High risk shipping distance (>75th percentile)\n",
    "    distance_threshold = df['shipping_distance_km'].quantile(risk_distance_quantile)\n",
    "    df['high_risk_distance'] = (df['shipping_distance_km'] > distance_threshold).astype(int)\n",
    "    \n",
    "    # Zero distance (billing = shipping, lower risk)\n",
    "    df['zero_distance'] = (df['shipping_distance_km'] == 0).astype(int)\n",
    "    \n",
    "    features = ['country_mismatch', 'high_risk_distance', 'zero_distance']\n",
    "    return df, features\n",
    "\n",
    "def create_security_features(df):\n",
    "    \"\"\"Create security verification-based features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Security score (count of passed verifications)\n",
    "    df['security_score'] = df['avs_match'] + df['cvv_result'] + df['three_ds_flag']\n",
    "    \n",
    "    # Count of failed verifications\n",
    "    df['verification_failures'] = 3 - df['security_score']\n",
    "    \n",
    "    # All verifications passed\n",
    "    df['all_verifications_passed'] = (df['security_score'] == 3).astype(int)\n",
    "    \n",
    "    # All verifications failed (high risk)\n",
    "    df['all_verifications_failed'] = (df['security_score'] == 0).astype(int)\n",
    "    \n",
    "    features = ['security_score', 'verification_failures', 'all_verifications_passed', 'all_verifications_failed']\n",
    "    return df, features\n",
    "\n",
    "def engineer_features(df, date_col='transaction_time', country_col='country'):\n",
    "    \"\"\"\n",
    "    Master function to create all engineered features.\n",
    "    Includes both UTC and local time-based features.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FEATURE ENGINEERING\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df_eng = df.copy()\n",
    "    all_new_features = []\n",
    "    \n",
    "    # 1. Convert to local time\n",
    "    print(\"\\n1. TIMEZONE CONVERSION:\")\n",
    "    df_eng = convert_utc_to_local_time(df_eng, date_col, country_col, timezone_mapping=get_country_timezone_mapping())\n",
    "    \n",
    "    # 2. Temporal features (UTC)\n",
    "    print(\"\\n2. TEMPORAL FEATURES (UTC):\")\n",
    "    df_eng, utc_features = create_temporal_features(df_eng, date_col, suffix='', late_night_hours=(23, 4), business_hours=(9, 17))\n",
    "    print(f\"  ‚úì Created {len(utc_features)} UTC temporal features\")\n",
    "    all_new_features.extend(utc_features)\n",
    "    \n",
    "    # 3. Temporal features (Local time)\n",
    "    print(\"\\n3. TEMPORAL FEATURES (LOCAL TIME):\")\n",
    "    df_eng, local_features = create_temporal_features(df_eng, 'local_time', suffix='_local', late_night_hours=(23, 4), business_hours=(9, 17))\n",
    "    print(f\"  ‚úì Created {len(local_features)} local time temporal features\")\n",
    "    all_new_features.extend(local_features)\n",
    "    \n",
    "    # 4. Amount features\n",
    "    print(\"\\n4. TRANSACTION AMOUNT FEATURES:\")\n",
    "    df_eng, amount_features = create_amount_features(df_eng)\n",
    "    print(f\"  ‚úì Created {len(amount_features)} amount-based features: {amount_features}\")\n",
    "    all_new_features.extend(amount_features)\n",
    "    \n",
    "    # 5. User behavior features\n",
    "    print(\"\\n5. USER BEHAVIOR FEATURES:\")\n",
    "    df_eng, behavior_features = create_user_behavior_features(df_eng)\n",
    "    print(f\"  ‚úì Created {len(behavior_features)} behavior features: {behavior_features}\")\n",
    "    all_new_features.extend(behavior_features)\n",
    "    \n",
    "    # 6. Geographic features\n",
    "    print(\"\\n6. GEOGRAPHIC FEATURES:\")\n",
    "    df_eng, geo_features = create_geographic_features(df_eng)\n",
    "    print(f\"  ‚úì Created {len(geo_features)} geographic features: {geo_features}\")\n",
    "    all_new_features.extend(geo_features)\n",
    "    \n",
    "    # 7. Security features\n",
    "    print(\"\\n7. SECURITY FEATURES:\")\n",
    "    df_eng, security_features = create_security_features(df_eng)\n",
    "    print(f\"  ‚úì Created {len(security_features)} security features: {security_features}\")\n",
    "    all_new_features.extend(security_features)\n",
    "    \n",
    "    # 8. Interaction features\n",
    "    print(\"\\n8. INTERACTION FEATURES (High-Risk Combinations):\")\n",
    "    # Define interaction feature configurations\n",
    "    interaction_config = [\n",
    "        {\n",
    "            'name': 'new_account_with_promo',\n",
    "            'conditions': ['is_new_account == 1', 'promo_used == 1'],\n",
    "            'operator': 'and'\n",
    "        },\n",
    "        {\n",
    "            'name': 'late_night_micro_transaction',\n",
    "            'conditions': ['is_late_night_local == 1', 'is_micro_transaction == 1'],\n",
    "            'operator': 'and'\n",
    "        },\n",
    "        {\n",
    "            'name': 'foreign_card_failed_verification',\n",
    "            'conditions': ['country_mismatch == 1', 'verification_failures > 0'],\n",
    "            'operator': 'and'\n",
    "        },\n",
    "        {\n",
    "            'name': 'new_high_velocity_account',\n",
    "            'conditions': ['is_new_account == 1', 'is_high_frequency_user == 1'],\n",
    "            'operator': 'and'\n",
    "        },\n",
    "        {\n",
    "            'name': 'high_value_long_distance',\n",
    "            'conditions': ['is_large_transaction == 1', 'high_risk_distance == 1'],\n",
    "            'operator': 'and'\n",
    "        },\n",
    "        {\n",
    "            'name': 'triple_risk_combo',\n",
    "            'conditions': ['is_new_account == 1', 'promo_used == 1', 'verification_failures > 0'],\n",
    "            'operator': 'and'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    df_eng, interaction_features = create_interaction_features(df_eng, interaction_config)\n",
    "    print(f\"  ‚úì Created {len(interaction_features)} interaction features: {interaction_features}\")\n",
    "    all_new_features.extend(interaction_features)\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"FEATURE ENGINEERING COMPLETE\")\n",
    "    print(f\"Total new features created: {len(all_new_features)}\")\n",
    "    print(f\"Original shape: {df.shape}\")\n",
    "    print(f\"New shape: {df_eng.shape}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return df_eng, all_new_features\n",
    "\n",
    "\n",
    "def print_feature_recommendations(corr_df, mi_df, vif_df, numeric_features, categorical_features):\n",
    "    \"\"\"Print comprehensive feature selection recommendations.\"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FEATURE SELECTION RECOMMENDATIONS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nüìä SUMMARY OF EDA FINDINGS:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(\"\\n1. NUMERIC FEATURES (Correlation Analysis):\")\n",
    "    print(\"   Features to KEEP (showing meaningful correlation):\")\n",
    "    for _, row in corr_df.head(5).iterrows():\n",
    "        print(f\"   ‚úì {row['feature']}: {row['correlation']:.4f} correlation\")\n",
    "    \n",
    "    print(\"\\n2. CATEGORICAL FEATURES (Mutual Information Analysis):\")\n",
    "    print(\"   Features to KEEP (MI > 0.01):\")\n",
    "    high_mi_features = mi_df[mi_df['mi_score'] > 0.01]\n",
    "    for _, row in high_mi_features.iterrows():\n",
    "        print(f\"   ‚úì {row['feature']}: MI = {row['mi_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\n3. MULTICOLLINEARITY CHECK:\")\n",
    "    if vif_df['VIF'].max() > 10:\n",
    "        high_vif_features = vif_df[vif_df['VIF'] > 10]\n",
    "        print(\"   ‚ö†Ô∏è  Consider removing or combining these features:\")\n",
    "        for _, row in high_vif_features.iterrows():\n",
    "            print(f\"   - {row['feature']}: VIF = {row['VIF']:.2f}\")\n",
    "    else:\n",
    "        print(\"   ‚úì No severe multicollinearity detected\")\n",
    "    \n",
    "    print(\"\\n4. TEMPORAL PATTERNS:\")\n",
    "    print(\"   ‚úì Hour of day shows fraud patterns (consider time-based features)\")\n",
    "    print(\"   ‚úì Weekend/weekday distinction may be relevant\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RECOMMENDED FEATURES FOR MODELING:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\n‚úÖ NUMERIC FEATURES (all 5):\")\n",
    "    for feat in numeric_features:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ CATEGORICAL FEATURES (all 8):\")\n",
    "    for feat in categorical_features:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ TEMPORAL FEATURES TO ENGINEER:\")\n",
    "    print(\"   ‚Ä¢ hour (from transaction_time)\")\n",
    "    print(\"   ‚Ä¢ day_of_week (from transaction_time)\")\n",
    "    print(\"   ‚Ä¢ is_weekend (derived from day_of_week)\")\n",
    "    print(\"   ‚Ä¢ is_midnight (hours 23-01)\")\n",
    "    \n",
    "    print(\"\\nüí° SUGGESTED FEATURE ENGINEERING:\")\n",
    "    print(\"   ‚Ä¢ country_mismatch: (country != bin_country)\")\n",
    "    print(\"   ‚Ä¢ amount_deviation: |amount - avg_amount_user|\")\n",
    "    print(\"   ‚Ä¢ amount_vs_avg_ratio: amount / avg_amount_user\")\n",
    "    print(\"   ‚Ä¢ high_risk_distance: (shipping_distance_km > threshold)\")\n",
    "    print(\"   ‚Ä¢ security_score: combination of avs_match + cvv_result + three_ds_flag\")\n",
    "    print(\"   ‚Ä¢ transaction_velocity: total_transactions_user / account_age_days\")\n",
    "    \n",
    "    print(\"\\n‚ö° MODELING CONSIDERATIONS:\")\n",
    "    print(\"   ‚Ä¢ Use stratified sampling (class imbalance: 44:1)\")\n",
    "    print(\"   ‚Ä¢ Apply class weights or SMOTE for minority class\")\n",
    "    print(\"   ‚Ä¢ Use appropriate metrics: ROC-AUC, F1, Precision-Recall (not accuracy)\")\n",
    "    print(\"   ‚Ä¢ Consider threshold tuning for precision/recall trade-off\")\n",
    "    print(\"   ‚Ä¢ Try tree-based models (handle categorical features well)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "def analyze_final_feature_selection(train_new_features):\n",
    "    \"\"\"\n",
    "    Comprehensive final feature selection analysis based on EDA insights\n",
    "    and engineered features. Returns categorized feature recommendations.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"FINAL FEATURE SELECTION FOR MODELING\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Define all available features\n",
    "    original_numeric = ['account_age_days', 'total_transactions_user', 'avg_amount_user',\n",
    "                       'amount', 'shipping_distance_km']\n",
    "    original_categorical = ['country', 'bin_country', 'channel', 'merchant_category',\n",
    "                           'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag']\n",
    "\n",
    "    print(\"\\nüìä AVAILABLE FEATURES:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Original features: {len(original_numeric) + len(original_categorical)}\")\n",
    "    print(f\"  ‚Ä¢ Numeric: {len(original_numeric)}\")\n",
    "    print(f\"  ‚Ä¢ Categorical: {len(original_categorical)}\")\n",
    "    print(f\"Engineered features: {len(train_new_features)}\")\n",
    "    print(f\"Total available: {len(original_numeric) + len(original_categorical) + len(train_new_features)}\")\n",
    "\n",
    "    # Categorize engineered features\n",
    "    temporal_utc = ['hour', 'day_of_week', 'month', 'is_weekend', 'is_late_night', 'is_business_hours']\n",
    "    temporal_local = ['hour_local', 'day_of_week_local', 'month_local', 'is_weekend_local',\n",
    "                     'is_late_night_local', 'is_business_hours_local']\n",
    "    amount_features = ['amount_deviation', 'amount_vs_avg_ratio', 'is_micro_transaction', 'is_large_transaction']\n",
    "    behavior_features = ['transaction_velocity', 'is_new_account', 'is_high_frequency_user']\n",
    "    geographic_features = ['country_mismatch', 'high_risk_distance', 'zero_distance']\n",
    "    security_features = ['security_score', 'verification_failures', 'all_verifications_passed', 'all_verifications_failed']\n",
    "    interaction_features = ['new_account_with_promo', 'late_night_micro_transaction',\n",
    "                           'foreign_card_failed_verification', 'new_high_velocity_account',\n",
    "                           'high_value_long_distance', 'triple_risk_combo']\n",
    "\n",
    "    print(\"\\nüîç FEATURE SELECTION ANALYSIS:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # 1. Original Features - Keep high-value ones\n",
    "    print(\"\\n1. ORIGINAL FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP ALL NUMERIC (5):\")\n",
    "    print(\"      ‚Ä¢ shipping_distance_km - Strong correlation (0.27)\")\n",
    "    print(\"      ‚Ä¢ amount - Moderate correlation (0.20)\")\n",
    "    print(\"      ‚Ä¢ account_age_days - Negative correlation (-0.12)\")\n",
    "    print(\"      ‚Ä¢ total_transactions_user, avg_amount_user - Baseline info\")\n",
    "\n",
    "    print(\"\\n   ‚úÖ KEEP HIGH-VALUE CATEGORICAL (5 of 8):\")\n",
    "    print(\"      ‚Ä¢ avs_match - High MI (0.017), 9.8% fraud when failed\")\n",
    "    print(\"      ‚Ä¢ cvv_result - High MI (0.015), 10.6% fraud when failed\")\n",
    "    print(\"      ‚Ä¢ three_ds_flag - High MI (0.010), 6.7% fraud when disabled\")\n",
    "    print(\"      ‚Ä¢ channel - High signal (3.6% fraud on web vs 0.8% on app)\")\n",
    "    print(\"      ‚Ä¢ promo_used - High signal (4.6% fraud when used)\")\n",
    "\n",
    "    print(\"\\n   ‚ö†Ô∏è  EXCLUDE (3 of 8) - Redundant with engineered features:\")\n",
    "    print(\"      ‚Ä¢ country ‚Üí Replaced by country_mismatch (more specific)\")\n",
    "    print(\"      ‚Ä¢ bin_country ‚Üí Replaced by country_mismatch\")\n",
    "    print(\"      ‚Ä¢ merchant_category ‚Üí Low signal, all categories near baseline\")\n",
    "\n",
    "    # 2. Temporal Features - Choose local over UTC\n",
    "    print(\"\\n2. TEMPORAL FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP LOCAL TIME FEATURES (6):\")\n",
    "    print(\"      ‚Ä¢ hour_local - Better captures 'unusual hour' fraud\")\n",
    "    print(\"      ‚Ä¢ is_late_night_local - Fraud scenario #1 (midnight transactions)\")\n",
    "    print(\"      ‚Ä¢ is_weekend_local, day_of_week_local, month_local\")\n",
    "    print(\"      ‚Ä¢ is_business_hours_local - Inverse of late_night signal\")\n",
    "\n",
    "    print(\"\\n   ‚ö†Ô∏è  EXCLUDE UTC FEATURES (6) - Redundant:\")\n",
    "    print(\"      ‚Ä¢ Local time is more meaningful for fraud detection\")\n",
    "    print(\"      ‚Ä¢ UTC features don't align with human behavior patterns\")\n",
    "\n",
    "    # 3. Amount Features - Keep all\n",
    "    print(\"\\n3. AMOUNT FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP ALL (4):\")\n",
    "    print(\"      ‚Ä¢ is_micro_transaction - Fraud scenario #1 ($1 card testing)\")\n",
    "    print(\"      ‚Ä¢ amount_vs_avg_ratio - User deviation signal\")\n",
    "    print(\"      ‚Ä¢ is_large_transaction - High-value fraud attempts\")\n",
    "    print(\"      ‚Ä¢ amount_deviation - Absolute deviation signal\")\n",
    "\n",
    "    # 4. Behavior Features - Keep all\n",
    "    print(\"\\n4. USER BEHAVIOR FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP ALL (3):\")\n",
    "    print(\"      ‚Ä¢ is_new_account - Fraud scenario #3 (fresh accounts)\")\n",
    "    print(\"      ‚Ä¢ transaction_velocity - Rapid account usage\")\n",
    "    print(\"      ‚Ä¢ is_high_frequency_user - Baseline comparison\")\n",
    "\n",
    "    # 5. Geographic Features - Keep all\n",
    "    print(\"\\n5. GEOGRAPHIC FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP ALL (3):\")\n",
    "    print(\"      ‚Ä¢ country_mismatch - Replaces country + bin_country\")\n",
    "    print(\"      ‚Ä¢ high_risk_distance - Fraud scenario #2 (5000km shipments)\")\n",
    "    print(\"      ‚Ä¢ zero_distance - Low-risk indicator\")\n",
    "\n",
    "    # 6. Security Features - Keep composite score only\n",
    "    print(\"\\n6. SECURITY FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP COMPOSITE SCORE (1 of 4):\")\n",
    "    print(\"      ‚Ä¢ security_score - Replaces individual avs/cvv/3ds flags\")\n",
    "\n",
    "    print(\"\\n   ‚ö†Ô∏è  EXCLUDE (3 of 4) - Redundant:\")\n",
    "    print(\"      ‚Ä¢ verification_failures ‚Üí Inverse of security_score\")\n",
    "    print(\"      ‚Ä¢ all_verifications_passed ‚Üí Encoded in security_score == 3\")\n",
    "    print(\"      ‚Ä¢ all_verifications_failed ‚Üí Encoded in security_score == 0\")\n",
    "    print(\"      Note: Keep original avs_match, cvv_result, three_ds_flag for interpretability\")\n",
    "\n",
    "    # 7. Interaction Features - Keep scenario-specific only\n",
    "    print(\"\\n7. INTERACTION FEATURES:\")\n",
    "    print(\"   ‚úÖ KEEP SCENARIO-SPECIFIC (3 of 6):\")\n",
    "    print(\"      ‚Ä¢ new_account_with_promo - Fraud scenario #3 (explicit)\")\n",
    "    print(\"      ‚Ä¢ late_night_micro_transaction - Fraud scenario #1 (explicit)\")\n",
    "    print(\"      ‚Ä¢ high_value_long_distance - Fraud scenario #2 variant\")\n",
    "\n",
    "    print(\"\\n   ‚ö†Ô∏è  EXCLUDE COMPOSITE INTERACTIONS (3 of 6):\")\n",
    "    print(\"      ‚Ä¢ foreign_card_failed_verification ‚Üí Covered by country_mismatch + security_score\")\n",
    "    print(\"      ‚Ä¢ new_high_velocity_account ‚Üí Covered by is_new_account + is_high_frequency_user\")\n",
    "    print(\"      ‚Ä¢ triple_risk_combo ‚Üí Overly specific, low frequency\")\n",
    "\n",
    "    # Final recommendations\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"FINAL FEATURE SET FOR MODELING\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Build final feature lists\n",
    "    final_numeric = original_numeric.copy()\n",
    "    final_categorical = ['channel', 'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag']\n",
    "    final_temporal = temporal_local.copy()\n",
    "    final_amount = amount_features.copy()\n",
    "    final_behavior = behavior_features.copy()\n",
    "    final_geographic = geographic_features.copy()\n",
    "    final_security = ['security_score']\n",
    "    final_interaction = ['new_account_with_promo', 'late_night_micro_transaction', 'high_value_long_distance']\n",
    "\n",
    "    all_final_features = (final_numeric + final_categorical + final_temporal +\n",
    "                         final_amount + final_behavior + final_geographic +\n",
    "                         final_security + final_interaction)\n",
    "\n",
    "    print(f\"\\nTotal features selected: {len(all_final_features)} (from {len(original_numeric) + len(original_categorical) + len(train_new_features)} available)\")\n",
    "    print(f\"Reduction: {len(original_numeric) + len(original_categorical) + len(train_new_features) - len(all_final_features)} features excluded\")\n",
    "\n",
    "    print(\"\\nüìã FINAL FEATURE LIST BY CATEGORY:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    print(f\"\\n1. Original Numeric ({len(final_numeric)}):\")\n",
    "    for feat in final_numeric:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n2. Original Categorical ({len(final_categorical)}):\")\n",
    "    for feat in final_categorical:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n3. Temporal (Local Time) ({len(final_temporal)}):\")\n",
    "    for feat in final_temporal:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n4. Amount Features ({len(final_amount)}):\")\n",
    "    for feat in final_amount:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n5. User Behavior ({len(final_behavior)}):\")\n",
    "    for feat in final_behavior:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n6. Geographic ({len(final_geographic)}):\")\n",
    "    for feat in final_geographic:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n7. Security ({len(final_security)}):\")\n",
    "    for feat in final_security:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(f\"\\n8. Interaction (Fraud Scenarios) ({len(final_interaction)}):\")\n",
    "    for feat in final_interaction:\n",
    "        print(f\"   ‚Ä¢ {feat}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"KEY DECISIONS:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"‚úì Local time > UTC time (better fraud signal)\")\n",
    "    print(\"‚úì country_mismatch > individual country fields (more specific)\")\n",
    "    print(\"‚úì security_score composite > individual flags (reduces dimensionality)\")\n",
    "    print(\"‚úì Kept original avs/cvv/3ds for interpretability despite redundancy\")\n",
    "    print(\"‚úì Scenario-specific interactions > generic combinations\")\n",
    "    print(\"‚úì Excluded merchant_category (low predictive value)\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "    return {\n",
    "        'numeric': final_numeric,\n",
    "        'categorical': final_categorical,\n",
    "        'temporal': final_temporal,\n",
    "        'amount': final_amount,\n",
    "        'behavior': final_behavior,\n",
    "        'geographic': final_geographic,\n",
    "        'security': final_security,\n",
    "        'interaction': final_interaction,\n",
    "        'all_features': all_final_features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d3e4f-c850-4597-99b2-1131a4ab89a0",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revrvtxo5o8",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data_csv(kaggle_source, data_dir, csv_file)\n",
    "input_df = load_data(f\"{data_dir}/{csv_file}\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cf89a-7b52-4ce8-86ba-074e98444e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ced16-83ae-461b-938b-f21a14af21f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No null values\n",
    "input_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862a07c5-f027-4b3b-b313-67e969143998",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "### Verify table grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f0951-7580-4b27-98e8-d301addb87ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Every row is uniquely defined by transaction and user id columns: {len(input_df)==len(input_df.drop_duplicates(subset=id_cols))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba466b7-3e7f-4f93-b743-9340becc68cc",
   "metadata": {},
   "source": [
    "### Target class balance\n",
    "Target class imbalance is investigated prior to train/validation/test split because stratified splitting is necessary to handle the large class imbalance present in this dataset (only 2.2% fraud). Modeling will require techniques such as stratified sampling, class weights, appropriate metrics, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qzjmrwuu47s",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_target_stats(input_df, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31970e7d-0e36-4592-ad2e-297ee774f7ad",
   "metadata": {},
   "source": [
    "### Convert date type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e04f33-2ed8-4081-abd5-44f4ecdbca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse timestamps as UTC timezone-aware (fail if timezone missing)\n",
    "input_df[date_feature] = pd.to_datetime(input_df[date_feature], utc=True, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6jfqm2m6xl2",
   "metadata": {},
   "source": [
    "### Feature stats\n",
    "Examine the distribution of categorical features and compute summary statistics for numerical features. Binary features (0/1 flags) are treated as categorical since they represent discrete states (see Setup, Define parameters section above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mue0cr826c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_feature_stats(input_df, id_cols, target_col, categorical_features, numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wzbb1mqfv5j",
   "metadata": {},
   "source": [
    "### Train/Validation/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f0a139-73b3-492c-be55-88998a854f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = split_train_val_test(\n",
    "    input_df, \n",
    "    target_col=target_col,\n",
    "    train_ratio=1 - val_ratio - test_ratio,\n",
    "    val_ratio=val_ratio, \n",
    "    test_ratio=test_ratio,\n",
    "    random_state=1,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b654355-530c-4fad-bfef-ec877abe6e8c",
   "metadata": {},
   "source": [
    "## EDA\n",
    "### Numeric features\n",
    "#### Calculate baseline metrics\n",
    "Define baseline fraud rate for comparison throughout EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zunse1qyqis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline fraud rate from training set\n",
    "baseline_fraud_rate = train_df[target_col].mean()\n",
    "print(f\"Baseline fraud rate: {baseline_fraud_rate:.4f} ({baseline_fraud_rate*100:.2f}%)\")\n",
    "print(f\"This will be used as a reference point throughout the EDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c1affe-ac59-4af2-a8aa-103b8ba4ce69",
   "metadata": {},
   "source": [
    "#### Visualize distributions of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cf99b4-a53b-4a6e-992f-624923fe52ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numeric_distributions(train_df, numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467d8a1f-40b9-405c-8e5f-64946117560e",
   "metadata": {},
   "source": [
    "#### Multicollinearity Detection (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6588c-bd29-4b59-8f3f-fa5b89c422f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vif_df = analyze_vif(train_df, numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec4922-9c2e-42a4-bac4-1eeab5a93dca",
   "metadata": {},
   "source": [
    "### Bivariate Analysis: Features vs. Target\n",
    "#### Calculate correlations with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1bf71-0a74-41b2-aebb-f75163feb545",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = analyze_correlations(train_df, numeric_features, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15505fc0-73d9-431a-a7cd-3ff258a7dda2",
   "metadata": {},
   "source": [
    "#### Box plots: Compare feature distributions between fraud and non-fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yd82febuh5q",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_box_plots(train_df, numeric_features, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pagq728khv8",
   "metadata": {},
   "source": [
    "### Temporal Analysis\n",
    "Analyze fraud patterns over time to identify temporal trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nn7uib5gn0m",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_temporal_patterns(train_df, date_feature, target_col, baseline_fraud_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1274e103-be4b-489f-9862-072ee8495fa5",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "#### Fraud Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec06196-7c0d-48b7-b8d8-3bc0d5160aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_categorical_fraud_rates(train_df, categorical_features, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dd195-fb36-42ad-aec6-63e22fc268f2",
   "metadata": {},
   "source": [
    "#### Visualize fraud rates for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ywo7htor9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorical_fraud_rates(train_df, categorical_features, target_col, baseline_fraud_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da4a718-12e9-4f76-97e1-b066dc83f11e",
   "metadata": {},
   "source": [
    "#### Calculate mutual information scores for categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpevjwmbhea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_df = analyze_mutual_information(train_df, categorical_features, target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec69343-8e91-4c4b-866b-ed7de8d08727",
   "metadata": {},
   "source": [
    "### Initial Feature Selection Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8153d0a-ad4a-4076-8ef6-38c3078b79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_feature_recommendations(corr_df, mi_df, vif_df, numeric_features, categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d625cb-6875-40a4-b84e-9138d8aa956f",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a577645-3919-401a-89a2-32c6591597e3",
   "metadata": {},
   "source": [
    "Apply feature engineering to create new predictive features. This includes:\n",
    "- **Temporal features** (UTC and local timezone): hour, day_of_week, is_weekend, is_late_night, is_business_hours\n",
    "- **Amount features**: amount_deviation, amount_vs_avg_ratio, micro/large transaction flags\n",
    "- **User behavior**: transaction_velocity, new_account, high_frequency_user\n",
    "- **Geographic**: country_mismatch, high_risk_distance, zero_distance\n",
    "- **Security**: security_score, verification_failures, all_verifications_passed/failed\n",
    "\n",
    "Local timezone conversion approximates transaction local time using the timezone of the user's country capital, enabling better detection of unusual-hour fraud patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pjq3flx019b",
   "metadata": {},
   "source": [
    "### Apply to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasnjccfr3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fe, train_new_features = engineer_features(train_df, date_col=date_feature, country_col='country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6sdw9iujexv",
   "metadata": {},
   "source": [
    "### Apply to validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpl4biyjqke",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_fe, _ = engineer_features(val_df, date_col=date_feature, country_col='country')\n",
    "test_fe, _ = engineer_features(test_df, date_col=date_feature, country_col='country')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iklhycsdy6",
   "metadata": {},
   "source": [
    "### Inspect engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brcav6qe4tj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display new features created\n",
    "print(f\"New features created ({len(train_new_features)}):\")\n",
    "for i, feat in enumerate(train_new_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "# Display sample rows with key engineered features\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Sample of engineered features:\")\n",
    "print(\"=\" * 80)\n",
    "sample_features = ['transaction_time', 'country', 'hour', 'hour_local', 'is_late_night', \n",
    "                  'is_late_night_local', 'amount', 'amount_vs_avg_ratio', \n",
    "                  'country_mismatch', 'security_score', 'is_fraud']\n",
    "display(train_fe[sample_features].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e2eeb-6dcd-4803-abc2-d444c2c85d91",
   "metadata": {},
   "source": [
    "## Final Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00040450-5cd1-4145-adf2-275dff681879",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = analyze_final_feature_selection(train_new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_feature_summary",
   "metadata": {},
   "source": [
    "### Store final feature lists for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "store_final_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store final feature lists as variables for easy access in modeling\n",
    "final_numeric_features = final_features['numeric']\n",
    "final_categorical_features = final_features['categorical']\n",
    "final_engineered_features = (\n",
    "    final_features['temporal'] + \n",
    "    final_features['amount'] + \n",
    "    final_features['behavior'] + \n",
    "    final_features['geographic'] + \n",
    "    final_features['security'] + \n",
    "    final_features['interaction']\n",
    ")\n",
    "final_all_features = final_features['all_features']\n",
    "\n",
    "print(f\"Final feature count: {len(final_all_features)}\")\n",
    "print(f\"  ‚Ä¢ Numeric: {len(final_numeric_features)}\")\n",
    "print(f\"  ‚Ä¢ Categorical: {len(final_categorical_features)}\")\n",
    "print(f\"  ‚Ä¢ Engineered: {len(final_engineered_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_datasets_header",
   "metadata": {},
   "source": [
    "## Save Feature Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ld84d93mon",
   "metadata": {},
   "outputs": [],
   "source": "# Create and save feature configuration for deployment\n# This config stores training-time statistics (quantile thresholds) needed for inference\nfeature_config = FeatureConfig.from_training_data(train_fe)\nfeature_config.save(\"../models/transformer_config.json\")\n\nprint(\"‚úì Saved feature configuration for deployment:\")\nprint(f\"  ‚Ä¢ models/transformer_config.json\")\nprint(f\"\\nTraining-time statistics (for inference):\")\nprint(f\"  ‚Ä¢ Amount threshold (95th): ${feature_config.amount_95th_percentile:.2f}\")\nprint(f\"  ‚Ä¢ Transaction threshold (75th): {feature_config.total_transactions_75th_percentile:.0f} transactions\")\nprint(f\"  ‚Ä¢ Distance threshold (75th): {feature_config.shipping_distance_75th_percentile:.2f} km\")\nprint(f\"  ‚Ä¢ Timezone mappings: {len(feature_config.timezone_mapping)} countries\")\nprint(f\"  ‚Ä¢ Final features: {len(feature_config.final_features)} features\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}