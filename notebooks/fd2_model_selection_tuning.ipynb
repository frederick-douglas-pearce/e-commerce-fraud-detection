{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# E-Commerce Fraud Detection - Modeling\n",
    "\n",
    "This notebook trains and evaluates machine learning models for fraud detection using the engineered features from `ec_fraud_detection.ipynb`.\n",
    "\n",
    "## Project Goal\n",
    "Deploy an optimally trained classification model capable of identifying fraudulent transactions with high precision and recall.\n",
    "\n",
    "## Modeling Approach\n",
    "1. Load pre-engineered features from EDA notebook\n",
    "2. Model-specific preprocessing (one-hot encoding, scaling)\n",
    "3. Baseline model training (Logistic Regression, Random Forest, XGBoost)\n",
    "4. Hyperparameter tuning\n",
    "5. Model evaluation with fraud-appropriate metrics\n",
    "6. Final model selection\n",
    "\n",
    "## Key Challenges\n",
    "- **Class Imbalance**: 44:1 ratio (97.8% normal, 2.2% fraud)\n",
    "- **Metric Selection**: **PR-AUC**, ROC-AUC, F1, Precision-Recall (not accuracy)\n",
    "- **Business Trade-off**: Balance false positives (customer friction) vs false negatives (fraud losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "### Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "parameters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths (relative to notebooks/ folder)\n",
    "data_path = \"../data/transactions.csv\"\n",
    "model_dir = \"../models\"  # Directory for saving model log files\n",
    "\n",
    "# Target column\n",
    "target_col = \"is_fraud\"\n",
    "\n",
    "# Random seed for reproducibility (matches train.py)\n",
    "random_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports_header",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Add project root to path for imports (needed when running from notebooks/ folder)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Standard library\n",
    "import json\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Sklearn - preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "# Sklearn - models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sklearn - model selection\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Project-specific preprocessing\n",
    "from src.deployment.preprocessing import FraudFeatureTransformer\n",
    "from src.deployment.evaluation.metrics import evaluate_model\n",
    "\n",
    "# fd2 notebook utilities\n",
    "from src.fd2_nb import (\n",
    "    create_search_object,\n",
    "    tune_with_logging,\n",
    "    analyze_cv_results,\n",
    "    track_xgboost_iterations,\n",
    "    analyze_cv_fold_variance\n",
    ")\n",
    "\n",
    "print(\"All packages imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_header",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Load the pre-engineered datasets with final selected features from the EDA notebook. Note that test data is completely held out of the model selection and tuning process in this notebook. It is used for final model evaluation in the last notebook, `fd3_model_evaluation_deployment.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw transaction data...\n",
      "Total samples: 299,695\n",
      "Fraud rate: 2.21%\n",
      "\n",
      "Split sizes:\n",
      "  \u2022 Training:   179,817 samples (60.0%)\n",
      "  \u2022 Validation: 59,939 samples (20.0%)\n",
      "\n",
      "Applying FraudFeatureTransformer...\n",
      "\u2713 Feature engineering complete\n",
      "\n",
      "Dataset shapes:\n",
      "  \u2022 Training:   (179817, 31)\n",
      "  \u2022 Validation: (59939, 31)\n",
      "  \u2022 Features:   30\n",
      "\n",
      "Feature columns:\n",
      "  ['account_age_days', 'total_transactions_user', 'avg_amount_user', 'amount', 'shipping_distance_km', 'channel', 'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag', 'hour_local', 'day_of_week_local', 'month_local', 'is_weekend_local', 'is_late_night_local', 'is_business_hours_local', 'amount_deviation', 'amount_vs_avg_ratio', 'is_micro_transaction', 'is_large_transaction', 'transaction_velocity', 'is_new_account', 'is_high_frequency_user', 'country_mismatch', 'high_risk_distance', 'zero_distance', 'security_score', 'new_account_with_promo', 'late_night_micro_transaction', 'high_value_long_distance']\n"
     ]
    }
   ],
   "source": [
    "# Load raw data and apply production transformer\n",
    "print(\"Loading raw transaction data...\")\n",
    "df = pd.read_csv(data_path, low_memory=False)\n",
    "\n",
    "# Split data (matching train.py exactly)\n",
    "print(f\"Total samples: {len(df):,}\")\n",
    "print(f\"Fraud rate: {df[target_col].mean():.2%}\")\n",
    "\n",
    "# 60/20/20 train/val/test split with stratification\n",
    "train_val_raw, _ = train_test_split(\n",
    "    df, test_size=0.2, stratify=df[target_col], random_state=random_seed\n",
    ")\n",
    "train_raw, val_raw = train_test_split(\n",
    "    train_val_raw, test_size=0.25, stratify=train_val_raw[target_col], random_state=random_seed\n",
    ")\n",
    "\n",
    "print(f\"\\nSplit sizes:\")\n",
    "print(f\"  \u2022 Training:   {len(train_raw):,} samples ({len(train_raw)/len(df)*100:.1f}%)\")\n",
    "print(f\"  \u2022 Validation: {len(val_raw):,} samples ({len(val_raw)/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Apply production feature engineering pipeline\n",
    "print(\"\\nApplying FraudFeatureTransformer...\")\n",
    "transformer = FraudFeatureTransformer()\n",
    "transformer.fit(train_raw)  # Fit only on training data\n",
    "\n",
    "# Transform all datasets\n",
    "train_features = transformer.transform(train_raw)\n",
    "val_features = transformer.transform(val_raw)\n",
    "\n",
    "# Add target column back\n",
    "train_df = train_features.copy()\n",
    "train_df[target_col] = train_raw[target_col].values\n",
    "\n",
    "val_df = val_features.copy()\n",
    "val_df[target_col] = val_raw[target_col].values\n",
    "\n",
    "print(\"\u2713 Feature engineering complete\")\n",
    "print(f\"\\nDataset shapes:\")\n",
    "print(f\"  \u2022 Training:   {train_df.shape}\")\n",
    "print(f\"  \u2022 Validation: {val_df.shape}\")\n",
    "print(f\"  \u2022 Features:   {train_features.shape[1]}\")\n",
    "\n",
    "print(f\"\\nFeature columns:\")\n",
    "print(f\"  {list(train_features.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inspect_header",
   "metadata": {},
   "source": [
    "### Inspect loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inspect_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_age_days</th>\n",
       "      <th>total_transactions_user</th>\n",
       "      <th>avg_amount_user</th>\n",
       "      <th>amount</th>\n",
       "      <th>shipping_distance_km</th>\n",
       "      <th>channel</th>\n",
       "      <th>promo_used</th>\n",
       "      <th>avs_match</th>\n",
       "      <th>cvv_result</th>\n",
       "      <th>three_ds_flag</th>\n",
       "      <th>...</th>\n",
       "      <th>is_new_account</th>\n",
       "      <th>is_high_frequency_user</th>\n",
       "      <th>country_mismatch</th>\n",
       "      <th>high_risk_distance</th>\n",
       "      <th>zero_distance</th>\n",
       "      <th>security_score</th>\n",
       "      <th>new_account_with_promo</th>\n",
       "      <th>late_night_micro_transaction</th>\n",
       "      <th>high_value_long_distance</th>\n",
       "      <th>is_fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91794</th>\n",
       "      <td>897</td>\n",
       "      <td>43</td>\n",
       "      <td>87.08</td>\n",
       "      <td>192.52</td>\n",
       "      <td>274.59</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38975</th>\n",
       "      <td>379</td>\n",
       "      <td>52</td>\n",
       "      <td>23.68</td>\n",
       "      <td>27.00</td>\n",
       "      <td>1205.83</td>\n",
       "      <td>app</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70887</th>\n",
       "      <td>398</td>\n",
       "      <td>55</td>\n",
       "      <td>117.75</td>\n",
       "      <td>142.58</td>\n",
       "      <td>473.93</td>\n",
       "      <td>app</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194632</th>\n",
       "      <td>1321</td>\n",
       "      <td>45</td>\n",
       "      <td>138.29</td>\n",
       "      <td>89.57</td>\n",
       "      <td>249.32</td>\n",
       "      <td>app</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288101</th>\n",
       "      <td>1727</td>\n",
       "      <td>40</td>\n",
       "      <td>83.10</td>\n",
       "      <td>56.47</td>\n",
       "      <td>515.39</td>\n",
       "      <td>app</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows \u00d7 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        account_age_days  total_transactions_user  avg_amount_user  amount  \\\n",
       "91794                897                       43            87.08  192.52   \n",
       "38975                379                       52            23.68   27.00   \n",
       "70887                398                       55           117.75  142.58   \n",
       "194632              1321                       45           138.29   89.57   \n",
       "288101              1727                       40            83.10   56.47   \n",
       "\n",
       "        shipping_distance_km channel  promo_used  avs_match  cvv_result  \\\n",
       "91794                 274.59     web           0          1           1   \n",
       "38975                1205.83     app           0          1           1   \n",
       "70887                 473.93     app           0          1           1   \n",
       "194632                249.32     app           0          1           1   \n",
       "288101                515.39     app           0          1           1   \n",
       "\n",
       "        three_ds_flag  ...  is_new_account  is_high_frequency_user  \\\n",
       "91794               1  ...               0                       0   \n",
       "38975               1  ...               0                       0   \n",
       "70887               1  ...               0                       0   \n",
       "194632              1  ...               0                       0   \n",
       "288101              1  ...               0                       0   \n",
       "\n",
       "        country_mismatch  high_risk_distance  zero_distance  security_score  \\\n",
       "91794                  0                   0              0               3   \n",
       "38975                  1                   1              0               3   \n",
       "70887                  0                   1              0               3   \n",
       "194632                 0                   0              0               3   \n",
       "288101                 1                   1              0               3   \n",
       "\n",
       "        new_account_with_promo  late_night_micro_transaction  \\\n",
       "91794                        0                             0   \n",
       "38975                        0                             0   \n",
       "70887                        0                             0   \n",
       "194632                       0                             0   \n",
       "288101                       0                             0   \n",
       "\n",
       "        high_value_long_distance  is_fraud  \n",
       "91794                          0         0  \n",
       "38975                          0         0  \n",
       "70887                          0         0  \n",
       "194632                         0         0  \n",
       "288101                         0         0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 179817 entries, 91794 to 27023\n",
      "Data columns (total 31 columns):\n",
      " #   Column                        Non-Null Count   Dtype  \n",
      "---  ------                        --------------   -----  \n",
      " 0   account_age_days              179817 non-null  int64  \n",
      " 1   total_transactions_user       179817 non-null  int64  \n",
      " 2   avg_amount_user               179817 non-null  float64\n",
      " 3   amount                        179817 non-null  float64\n",
      " 4   shipping_distance_km          179817 non-null  float64\n",
      " 5   channel                       179817 non-null  object \n",
      " 6   promo_used                    179817 non-null  int64  \n",
      " 7   avs_match                     179817 non-null  int64  \n",
      " 8   cvv_result                    179817 non-null  int64  \n",
      " 9   three_ds_flag                 179817 non-null  int64  \n",
      " 10  hour_local                    179817 non-null  int32  \n",
      " 11  day_of_week_local             179817 non-null  int32  \n",
      " 12  month_local                   179817 non-null  int32  \n",
      " 13  is_weekend_local              179817 non-null  int64  \n",
      " 14  is_late_night_local           179817 non-null  int64  \n",
      " 15  is_business_hours_local       179817 non-null  int64  \n",
      " 16  amount_deviation              179817 non-null  float64\n",
      " 17  amount_vs_avg_ratio           179817 non-null  float64\n",
      " 18  is_micro_transaction          179817 non-null  int64  \n",
      " 19  is_large_transaction          179817 non-null  int64  \n",
      " 20  transaction_velocity          179817 non-null  float64\n",
      " 21  is_new_account                179817 non-null  int64  \n",
      " 22  is_high_frequency_user        179817 non-null  int64  \n",
      " 23  country_mismatch              179817 non-null  int64  \n",
      " 24  high_risk_distance            179817 non-null  int64  \n",
      " 25  zero_distance                 179817 non-null  int64  \n",
      " 26  security_score                179817 non-null  int64  \n",
      " 27  new_account_with_promo        179817 non-null  int64  \n",
      " 28  late_night_micro_transaction  179817 non-null  int64  \n",
      " 29  high_value_long_distance      179817 non-null  int64  \n",
      " 30  is_fraud                      179817 non-null  int64  \n",
      "dtypes: float64(6), int32(3), int64(21), object(1)\n",
      "memory usage: 41.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Target distribution (training set):\n",
      "is_fraud\n",
      "0    175850\n",
      "1      3967\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Fraud rate: 0.0221 (2.21%)\n",
      "Class imbalance ratio: 44.3:1\n"
     ]
    }
   ],
   "source": [
    "# Display first few rows\n",
    "print(\"Training data sample:\")\n",
    "display(train_df.head())\n",
    "display(train_df.info())\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nTarget distribution (training set):\")\n",
    "fraud_rate = train_df[target_col].mean()\n",
    "print(train_df[target_col].value_counts())\n",
    "print(f\"\\nFraud rate: {fraud_rate:.4f} ({fraud_rate*100:.2f}%)\")\n",
    "print(f\"Class imbalance ratio: {(1-fraud_rate)/fraud_rate:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_types_header",
   "metadata": {},
   "source": [
    "### Identify feature types\n",
    "Categorize features for preprocessing pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feature_types",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature breakdown:\n",
      "  \u2022 Total features: 30\n",
      "  \u2022 Numeric features: 26\n",
      "  \u2022 Categorical features: 1\n",
      "  \u2022 Binary features (int encoded): 16\n",
      "\n",
      "Numeric features (26):\n",
      "  ['account_age_days', 'total_transactions_user', 'avg_amount_user', 'amount', 'shipping_distance_km', 'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag', 'is_weekend_local', 'is_late_night_local', 'is_business_hours_local', 'amount_deviation', 'amount_vs_avg_ratio', 'is_micro_transaction', 'is_large_transaction', 'transaction_velocity', 'is_new_account', 'is_high_frequency_user', 'country_mismatch', 'high_risk_distance', 'zero_distance', 'security_score', 'new_account_with_promo', 'late_night_micro_transaction', 'high_value_long_distance']\n",
      "\n",
      "Categorical features (1):\n",
      "  ['channel']\n",
      "\n",
      "Binary features (16):\n",
      "  ['promo_used', 'avs_match', 'cvv_result', 'three_ds_flag', 'is_weekend_local', 'is_late_night_local', 'is_business_hours_local', 'is_micro_transaction', 'is_large_transaction', 'is_new_account', 'is_high_frequency_user', 'country_mismatch', 'high_risk_distance', 'new_account_with_promo', 'late_night_micro_transaction', 'high_value_long_distance']\n"
     ]
    }
   ],
   "source": [
    "# Separate target from features\n",
    "feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "# Identify numeric vs categorical features\n",
    "numeric_features = train_df[feature_cols].select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = train_df[feature_cols].select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# For binary features that might be stored as int, we may want to treat them as categorical\n",
    "# Check for binary features in numeric columns\n",
    "binary_features = []\n",
    "for col in numeric_features:\n",
    "    unique_vals = train_df[col].nunique()\n",
    "    if unique_vals == 2:\n",
    "        binary_features.append(col)\n",
    "\n",
    "print(f\"Feature breakdown:\")\n",
    "print(f\"  \u2022 Total features: {len(feature_cols)}\")\n",
    "print(f\"  \u2022 Numeric features: {len(numeric_features)}\")\n",
    "print(f\"  \u2022 Categorical features: {len(categorical_features)}\")\n",
    "print(f\"  \u2022 Binary features (int encoded): {len(binary_features)}\")\n",
    "\n",
    "print(f\"\\nNumeric features ({len(numeric_features)}):\")\n",
    "print(f\"  {numeric_features}\")\n",
    "\n",
    "print(f\"\\nCategorical features ({len(categorical_features)}):\")\n",
    "print(f\"  {categorical_features}\")\n",
    "\n",
    "if binary_features:\n",
    "    print(f\"\\nBinary features ({len(binary_features)}):\")\n",
    "    print(f\"  {binary_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qhrpwv4fdy8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature categorization for preprocessing:\n",
      "  \u2022 Continuous numeric: 12\n",
      "  \u2022 Categorical: 5\n",
      "  \u2022 Binary: 13\n",
      "  \u2022 Total: 30\n",
      "\n",
      "\u2713 All 30 features categorized correctly\n"
     ]
    }
   ],
   "source": [
    "# Properly categorize features for model-specific preprocessing\n",
    "# Based on the 30 features from FraudFeatureTransformer\n",
    "\n",
    "# Continuous numeric features (need scaling for Logistic Regression)\n",
    "continuous_numeric = [\n",
    "    'account_age_days', 'total_transactions_user', 'avg_amount_user', \n",
    "    'amount', 'shipping_distance_km', 'hour_local', 'day_of_week_local',\n",
    "    'month_local', 'amount_deviation', 'amount_vs_avg_ratio', \n",
    "    'transaction_velocity', 'security_score'\n",
    "]\n",
    "\n",
    "# Categorical features (need encoding)\n",
    "categorical = ['channel', 'promo_used', 'avs_match', 'cvv_result', 'three_ds_flag']\n",
    "\n",
    "# Binary features (already 0/1, no preprocessing needed)\n",
    "binary = [\n",
    "    'is_weekend_local', 'is_late_night_local', 'is_business_hours_local',\n",
    "    'is_micro_transaction', 'is_large_transaction', 'is_new_account',\n",
    "    'is_high_frequency_user', 'country_mismatch', 'high_risk_distance',\n",
    "    'zero_distance', 'new_account_with_promo', 'late_night_micro_transaction',\n",
    "    'high_value_long_distance'\n",
    "]\n",
    "\n",
    "print(\"Feature categorization for preprocessing:\")\n",
    "print(f\"  \u2022 Continuous numeric: {len(continuous_numeric)}\")\n",
    "print(f\"  \u2022 Categorical: {len(categorical)}\")\n",
    "print(f\"  \u2022 Binary: {len(binary)}\")\n",
    "print(f\"  \u2022 Total: {len(continuous_numeric) + len(categorical) + len(binary)}\")\n",
    "\n",
    "# Verify all 30 features are accounted for\n",
    "all_features = continuous_numeric + categorical + binary\n",
    "assert len(all_features) == 30, f\"Expected 30 features, got {len(all_features)}\"\n",
    "print(\"\\n\u2713 All 30 features categorized correctly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocessing_header",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Apply model-specific preprocessing transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "uhd8rfnz92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2713 Preprocessing pipelines created:\n",
      "  \u2022 Logistic Regression: StandardScaler + OneHotEncoder\n",
      "  \u2022 Tree-based models: OrdinalEncoder (minimal)\n"
     ]
    }
   ],
   "source": [
    "# Create preprocessing pipelines for different model types\n",
    "\n",
    "# For Logistic Regression: Scale numeric + One-hot encode categorical\n",
    "logistic_preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), continuous_numeric),\n",
    "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical),\n",
    "    ('binary', 'passthrough', binary)\n",
    "], remainder='drop')\n",
    "\n",
    "# For tree-based models: Simple ordinal encoding (optional, trees can handle categoricals)\n",
    "# Using OrdinalEncoder for categorical features, passthrough for rest\n",
    "tree_preprocessor = ColumnTransformer([\n",
    "    ('cat', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1), categorical),\n",
    "    ('rest', 'passthrough', continuous_numeric + binary)\n",
    "], remainder='drop')\n",
    "\n",
    "print(\"\u2713 Preprocessing pipelines created:\")\n",
    "print(\"  \u2022 Logistic Regression: StandardScaler + OneHotEncoder\")\n",
    "print(\"  \u2022 Tree-based models: OrdinalEncoder (minimal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline_header",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "Train initial models to establish performance baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b4484f-e6eb-4446-8772-63482b5c2f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "y_train = train_df[target_col]\n",
    "\n",
    "X_val = val_df.drop(columns=[target_col])\n",
    "y_val = val_df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3opuyu13q0h",
   "metadata": {},
   "source": [
    "### Baseline 1: Logistic Regression\n",
    "Linear model with StandardScaler + OneHotEncoder. Handles class imbalance with `class_weight='balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nq69bso9q98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "\n",
      "====================================================================================================\n",
      "Logistic Regression - Validation Set Performance\n",
      "====================================================================================================\n",
      "  PR-AUC:    0.6973\n",
      "  ROC-AUC:   0.9662\n",
      "  Precision: 0.2050 (20.50%)\n",
      "  Recall:    0.8934 (89.34%)\n",
      "  F1 Score:  0.3334\n",
      "\n",
      "Confusion Matrix:\n",
      "  TN: 54,031  |  FP: 4,585\n",
      "  FN: 141  |  TP: 1,182\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\u2713 Logistic Regression baseline trained\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression baseline\n",
    "print(\"Training Logistic Regression...\")\n",
    "\n",
    "# Create pipeline\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('preprocessor', logistic_preprocessor),\n",
    "    ('classifier', LogisticRegression(\n",
    "        class_weight='balanced',  # Handle class imbalance\n",
    "        max_iter=1000,\n",
    "        random_state=random_seed\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "logistic_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "logistic_metrics = evaluate_model(\n",
    "    logistic_pipeline, \n",
    "    X_val, \n",
    "    y_val, \n",
    "    model_name=\"Logistic Regression\",\n",
    "    dataset_name=\"Validation\"\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Logistic Regression baseline trained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "msg8xti2eho",
   "metadata": {},
   "source": [
    "### Baseline 2: Random Forest\n",
    "Tree-based ensemble model with minimal preprocessing. Handles class imbalance with `class_weight='balanced'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9jskw54l9ep",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest...\n",
      "\n",
      "====================================================================================================\n",
      "Random Forest - Validation Set Performance\n",
      "====================================================================================================\n",
      "  PR-AUC:    0.8482\n",
      "  ROC-AUC:   0.9627\n",
      "  Precision: 0.9384 (93.84%)\n",
      "  Recall:    0.7143 (71.43%)\n",
      "  F1 Score:  0.8112\n",
      "\n",
      "Confusion Matrix:\n",
      "  TN: 58,554  |  FP: 62\n",
      "  FN: 378  |  TP: 945\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\u2713 Random Forest baseline trained\n"
     ]
    }
   ],
   "source": [
    "# Train Random Forest baseline\n",
    "print(\"Training Random Forest...\")\n",
    "\n",
    "# Create pipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', tree_preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        class_weight='balanced',  # Handle class imbalance\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1  # Use all cores\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "rf_metrics = evaluate_model(\n",
    "    rf_pipeline, \n",
    "    X_val, \n",
    "    y_val, \n",
    "    model_name=\"Random Forest\",\n",
    "    dataset_name=\"Validation\"\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 Random Forest baseline trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9xpaf5j3034",
   "metadata": {},
   "source": [
    "### Baseline 3: XGBoost\n",
    "Gradient boosting model with minimal preprocessing. Handles class imbalance with `scale_pos_weight` (ratio of negative to positive class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9to98qgw5o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost...\n",
      "Class imbalance ratio: 44.3:1\n",
      "Using scale_pos_weight=44.3\n",
      "\n",
      "====================================================================================================\n",
      "XGBoost - Validation Set Performance\n",
      "====================================================================================================\n",
      "  PR-AUC:    0.8458\n",
      "  ROC-AUC:   0.9667\n",
      "  Precision: 0.5542 (55.42%)\n",
      "  Recall:    0.8466 (84.66%)\n",
      "  F1 Score:  0.6699\n",
      "\n",
      "Confusion Matrix:\n",
      "  TN: 57,715  |  FP: 901\n",
      "  FN: 203  |  TP: 1,120\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "\u2713 XGBoost baseline trained\n"
     ]
    }
   ],
   "source": [
    "# Train XGBoost baseline\n",
    "print(\"Training XGBoost...\")\n",
    "\n",
    "# Calculate scale_pos_weight for class imbalance\n",
    "# scale_pos_weight = (# negative class) / (# positive class)\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"Class imbalance ratio: {scale_pos_weight:.1f}:1\")\n",
    "print(f\"Using scale_pos_weight={scale_pos_weight:.1f}\")\n",
    "\n",
    "# Create pipeline\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', tree_preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        scale_pos_weight=scale_pos_weight,  # Handle class imbalance\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1,  # Use all cores\n",
    "        eval_metric='logloss'  # Suppress warning\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Train\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "xgb_metrics = evaluate_model(\n",
    "    xgb_pipeline, \n",
    "    X_val, \n",
    "    y_val, \n",
    "    model_name=\"XGBoost\",\n",
    "    dataset_name=\"Validation\"\n",
    ")\n",
    "\n",
    "print(\"\\n\u2713 XGBoost baseline trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0gzjizyn465u",
   "metadata": {},
   "source": [
    "### Baseline Model Comparison\n",
    "Compare all baseline models on key fraud detection metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pqfaa53277o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table using compare_models utility\n",
    "comparison_df = compare_models(\n",
    "    [\n",
    "        {'model': 'Logistic Regression', **logistic_metrics},\n",
    "        {'model': 'Random Forest', **rf_metrics},\n",
    "        {'model': 'XGBoost', **xgb_metrics}\n",
    "    ],\n",
    "    title=\"BASELINE MODEL COMPARISON - Validation Set\",\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE MODEL COMPARISON - Validation Set\")\n",
    "print(\"=\"*80)\n",
    "display(comparison_df.style.format({\n",
    "    'roc_auc': '{:.4f}',\n",
    "    'pr_auc': '{:.4f}',\n",
    "    'f1': '{:.4f}',\n",
    "    'precision': '{:.4f}',\n",
    "    'recall': '{:.4f}',\n",
    "    'accuracy': '{:.4f}'\n",
    "}).background_gradient(cmap='RdYlGn', subset=['roc_auc', 'pr_auc', 'f1']))\n",
    "\n",
    "# Identify best model for each metric\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Best Performing Model by Metric:\")\n",
    "print(\"=\"*80)\n",
    "for metric in ['roc_auc', 'pr_auc', 'f1', 'precision', 'recall']:\n",
    "    best_model = comparison_df[metric].idxmax()\n",
    "    best_value = comparison_df[metric].max()\n",
    "    print(f\"  {metric.upper():15s}: {best_model:20s} ({best_value:.4f})\")\n",
    "print(\"=\"*80)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q9c119q21ue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Key metrics comparison (ROC-AUC, PR-AUC, F1)\n",
    "ax = axes[0]\n",
    "metrics_to_plot = ['roc_auc', 'pr_auc', 'f1']\n",
    "comparison_df[metrics_to_plot].plot(kind='bar', ax=ax, color=['steelblue', 'coral', 'lightgreen'])\n",
    "ax.set_title('Key Fraud Detection Metrics Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticklabels(comparison_df.index, rotation=45, ha='right')\n",
    "ax.legend(['ROC-AUC', 'PR-AUC', 'F1 Score'], loc='lower right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Plot 2: Precision vs Recall tradeoff\n",
    "ax = axes[1]\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['precision'], width, label='Precision', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, comparison_df['recall'], width, label='Recall', color='coral')\n",
    "\n",
    "ax.set_title('Precision vs Recall Tradeoff', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Model', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# Add value labels on bars\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Baseline model comparison complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v9n2mhnzusk",
   "metadata": {},
   "source": [
    "### Key Insights from Baseline Models\n",
    "\n",
    "**Observations:**\n",
    "- All models show reasonable performance on the highly imbalanced dataset (44:1 ratio)\n",
    "- Class imbalance handling (class_weight/scale_pos_weight) is working effectively\n",
    "- Tree-based models (Random Forest, XGBoost) typically outperform Logistic Regression on this data\n",
    "\n",
    "**Next Steps:**\n",
    "1. **Hyperparameter Tuning**: Optimize the best performing baseline model(s)\n",
    "2. **Threshold Optimization**: Tune prediction threshold to balance precision/recall based on business requirements\n",
    "3. **Feature Importance**: Analyze which features contribute most to fraud detection\n",
    "4. **Test Set Evaluation**: Final evaluation on held-out test set\n",
    "\n",
    "**Metric Selection Guide:**\n",
    "- **ROC-AUC**: Overall model discrimination ability (higher is better)\n",
    "- **PR-AUC**: Performance on imbalanced data (more important than ROC-AUC for fraud)\n",
    "- **F1 Score**: Balance between precision and recall\n",
    "- **Precision**: Minimize false positives (customer friction)\n",
    "- **Recall**: Catch as many frauds as possible (minimize losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h8yv24m1ga",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Optimize model parameters for best performance using the best performing baseline models (Random Forest and XGBoost).\n",
    "\n",
    "### Tuning Strategy\n",
    "\n",
    "Based on baseline results, we'll tune **Random Forest** and **XGBoost** - the two best performing models with excellent false positive control.\n",
    "\n",
    "**Optimization Approach:**\n",
    "- **Method**: RandomizedSearchCV (40 iterations for efficient exploration)\n",
    "- **Metric**: PR-AUC (Precision-Recall AUC) - ideal for 44:1 class imbalance\n",
    "- **Cross-Validation**: 4-fold Stratified CV on training set\n",
    "- **Validation Set**: Held out for unbiased final comparison\n",
    "\n",
    "**Why PR-AUC?**\n",
    "- More informative than ROC-AUC for imbalanced datasets\n",
    "- Focuses on minority class (fraud) performance\n",
    "- Directly measures precision-recall trade-off\n",
    "- Aligns with business goals (catch fraud, minimize false alarms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x1li0ari30m",
   "metadata": {},
   "source": [
    "### Prepare Combined Train+Validation Dataset for Hyperparameter Tuning\n",
    "\n",
    "**Important ML Best Practice:**\n",
    "\n",
    "We combine the training and validation datasets BEFORE running GridSearchCV for hyperparameter tuning. This is the correct methodology because:\n",
    "\n",
    "1. **GridSearchCV uses internal cross-validation**: It automatically splits the data into K folds (we use 4) for hyperparameter evaluation\n",
    "2. **More data for tuning**: Gives GridSearchCV access to 80% of data (train+val) instead of just 60% (train only)\n",
    "3. **Better hyperparameter selection**: More samples lead to more reliable cross-validation results\n",
    "4. **No data leakage**: GridSearchCV's internal CV ensures the validation fold is never used during training\n",
    "\n",
    "**Why not just use the separate validation set?**\n",
    "- Using a manual validation set for hyperparameter tuning would mean less data for GridSearchCV\n",
    "- GridSearchCV's built-in cross-validation is more robust than a single train/val split\n",
    "- The final model will be evaluated on a completely held-out test set\n",
    "\n",
    "**Process:**\n",
    "1. Combine train_df and val_df \u2192 train_val_df (80% of original data)\n",
    "2. Run GridSearchCV on train_val_df with 4-fold CV\n",
    "3. GridSearchCV's `best_estimator_` is automatically retrained on the full train_val_df\n",
    "4. Evaluate final model on test data (20% held-out) in separate notebook (`fd3_model_evaluation_deployment.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i13i1oer7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and validation for hyperparameter tuning\n",
    "# This follows ML best practices: GridSearchCV will use 4-fold CV internally\n",
    "# Gives GridSearchCV access to 80% of data instead of just 60%\n",
    "train_val_df = pd.concat([train_df, val_df], axis=0, ignore_index=True)\n",
    "\n",
    "# Separate features and target for the combined dataset\n",
    "X_train_val = train_val_df.drop(columns=[target_col])\n",
    "y_train_val = train_val_df[target_col]\n",
    "\n",
    "print(\"Dataset Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Combined train+val: {len(train_val_df):,} samples ({len(train_df):,} train + {len(val_df):,} val)\")\n",
    "print(f\"  \u2022 Features: {X_train_val.shape[1]}\")\n",
    "print(f\"  \u2022 Fraud rate: {y_train_val.mean():.4f} ({y_train_val.mean()*100:.2f}%)\")\n",
    "print(\"\\nNote: X_train_val and y_train_val will be used for GridSearchCV hyperparameter tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85q61kj3tb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=4, shuffle=True, random_state=random_seed)\n",
    "\n",
    "print(\"\u2713 Cross-validation strategy defined:\")\n",
    "print(f\"  \u2022 Method: 4-Fold Stratified CV\")\n",
    "print(f\"  \u2022 Preserves 2.2% fraud rate in each fold\")\n",
    "print(f\"  \u2022 Random seed: {random_seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8rol2rcawcs",
   "metadata": {},
   "source": [
    "### Tune Random Forest\n",
    "Baseline performance: PR-AUC=0.8456, Precision=94.19%, Recall=71.13%\n",
    "\n",
    "Goal: Improve recall while maintaining high precision (minimize false positives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vk2x2csrfx",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuning Random Forest...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# SEARCH CONFIGURATION - easily switch between Grid and Random search\n",
    "# Note that I have not included the random search as it took > 30 minutes to run\n",
    "# Logs of previous runs can be viewed at models/logs/*.txt\n",
    "search_type = 'grid'  # Options: 'grid' for GridSearchCV, 'random' for RandomizedSearchCV\n",
    "n_iter = 40  # Only used if search_type='random'\n",
    "\n",
    "# Define hyperparameter grid\n",
    "# UPDATED based on bias-variance analysis (see analysis/bias_variance/)\n",
    "# Changes: Increased regularization to reduce overfitting\n",
    "#   - Reduced max_depth from [25, 30] to [20, 25]\n",
    "#   - Increased min_samples_split from [2] to [5, 10]\n",
    "#   - Increased min_samples_leaf from [2] to [5, 10]\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [350, 400, 450],\n",
    "    'classifier__max_depth': [15, 20],  # REDUCED from [25, 30]\n",
    "    'classifier__min_samples_split': [10],  # INCREASED from [2]\n",
    "    'classifier__min_samples_leaf': [5],  # INCREASED from [2]\n",
    "    'classifier__max_features': ['sqrt'],\n",
    "    'classifier__class_weight': ['balanced_subsample']\n",
    "}\n",
    "\n",
    "print(f\"Hyperparameter search space:\")\n",
    "print(f\"  \u2022 n_estimators: {param_grid_rf['classifier__n_estimators']}\")\n",
    "print(f\"  \u2022 max_depth: {param_grid_rf['classifier__max_depth']}\")\n",
    "print(f\"  \u2022 min_samples_split: {param_grid_rf['classifier__min_samples_split']}\")\n",
    "print(f\"  \u2022 min_samples_leaf: {param_grid_rf['classifier__min_samples_leaf']}\")\n",
    "print(f\"  \u2022 max_features: {param_grid_rf['classifier__max_features']}\")\n",
    "print(f\"  \u2022 class_weight: {param_grid_rf['classifier__class_weight']}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"NOTE: Updated hyperparameters to reduce overfitting (14.8% train-val gap)\")\n",
    "print(\"      See analysis/bias_variance/ANALYSIS_SUMMARY.md for details\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create base pipeline\n",
    "rf_base_pipeline = Pipeline([\n",
    "    ('preprocessor', tree_preprocessor),\n",
    "    ('classifier', RandomForestClassifier(\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Create search object (Grid or Random based on search_type)\n",
    "rf_search = create_search_object(\n",
    "    search_type=search_type,\n",
    "    estimator=rf_base_pipeline,\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='average_precision',  # PR-AUC\n",
    "    cv=cv_strategy,\n",
    "    n_iter=n_iter,  # Only used for RandomizedSearchCV\n",
    "    verbose=1,  # Minimal output (CSV has all details)\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit with logging\n",
    "# Using X_train_val and y_train_val gives GridSearchCV access to 80% of data (train+val)\n",
    "# instead of just 60% (train only), leading to better hyperparameter selection\n",
    "rf_search, rf_log_path, rf_cv_results_path = tune_with_logging(\n",
    "    rf_search, \n",
    "    X_train_val,  # Changed from X_train\n",
    "    y_train_val,  # Changed from y_train\n",
    "    model_name='random_forest'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p726pupz85j",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_rf = compare_models(\n",
    "    [\n",
    "        {'model': 'Random Forest (Baseline)', **rf_metrics},\n",
    "        {'model': 'Random Forest (Tuned)', **rf_tuned_metrics}\n",
    "    ],\n",
    "    verbose=False\n",
    ")\n",
    "display(comparison_rf)\n",
    "\n",
    "print(\"\\nImprovement from tuning:\")\n",
    "for metric in ['pr_auc', 'roc_auc', 'f1', 'precision', 'recall']:\n",
    "    baseline_val = comparison_rf.loc['Random Forest (Baseline)', metric]\n",
    "    tuned_val = comparison_rf.loc['Random Forest (Tuned)', metric]\n",
    "    improvement = tuned_val - baseline_val\n",
    "    improvement_pct = (improvement / baseline_val) * 100\n",
    "    print(f\"  {metric.upper():12s}: {improvement:+.4f} ({improvement_pct:+.1f}%)\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "te70kv3ld6r",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Random Forest CV results for production considerations\n",
    "rf_top_candidates = analyze_cv_results(rf_cv_results_path, top_n=5, model_name=\"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1q6n5jeikz6",
   "metadata": {},
   "source": [
    "#### CV Results Analysis - Important Caveats\n",
    "\n",
    "**Timing Measurements:**\n",
    "- **\u26a0 Parallel Processing Artifacts**: When using `n_jobs=-1`, timing measurements can be unreliable due to parallel scheduling overhead, CPU core allocation variance, and wall-clock vs CPU time differences\n",
    "- **\u26a0 Measurement Noise**: Small timing differences (< 20-30%) are often just noise, especially with GridSearchCV on small search spaces\n",
    "- **\u26a0 Not Production-Representative**: CV timing includes data splitting, transformation, and fold iteration overhead that won't exist in production inference\n",
    "\n",
    "**Model Stability:**\n",
    "- **\u2713 Reliable Metric**: `std_test_score` accurately reflects model consistency across CV folds\n",
    "- **\u2713 Production-Relevant**: Low variance indicates robust performance on different data samples\n",
    "\n",
    "**Performance Metrics (PR-AUC):**\n",
    "- **\u2713 Reliable Metric**: `mean_test_score` is the most trustworthy metric from CV results\n",
    "- **\u2713 Use for Model Selection**: Focus primarily on PR-AUC when choosing between candidates\n",
    "\n",
    "**Recommendation:**\n",
    "- Use CV timing as **rough indicators only** - don't over-optimize based on small differences\n",
    "- **Production latency testing** (API deployment) will provide the definitive performance numbers\n",
    "- If latency issues arise in production, revisit model selection favoring simpler models with minimal PR-AUC cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mo0fjbya24b",
   "metadata": {},
   "source": [
    "### Tune XGBoost\n",
    "Baseline performance: PR-AUC=0.8460, Precision=54.78%, Recall=84.05%\n",
    "\n",
    "Goal: Improve precision-recall balance (currently recall is high but precision is low)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3tn7585l5dn",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tuning XGBoost...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# SEARCH CONFIGURATION - easily switch between Grid and Random search\n",
    "# Note that I have not included the random search as it took > 30 minutes to run\n",
    "# Logs of previous runs can be viewed at models/logs/*.txt\n",
    "search_type = 'grid'  # Options: 'grid' for GridSearchCV, 'random' for RandomizedSearchCV\n",
    "n_iter = 40  # Only used if search_type='random'\n",
    "\n",
    "# Define hyperparameter grid\n",
    "# UPDATED based on bias-variance analysis (see analysis/bias_variance/)\n",
    "# Changes: Increased regularization to reduce overfitting (12.8% train-val gap)\n",
    "#   - Optimal stopping at ~92 iterations, so keeping n_estimators around 90-100\n",
    "#   - Increased min_child_weight from [5] to [7, 10]\n",
    "#   - Increased gamma from [0.5, 0.6] to [0.7, 0.8, 1.0]\n",
    "#   - Added L1 regularization: reg_alpha [0.0, 0.1]\n",
    "#   - Added L2 regularization: reg_lambda [1.0, 2.0]\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [90, 100, 110],  # Centered around optimal 92\n",
    "    'classifier__max_depth': [4],\n",
    "    'classifier__learning_rate': [0.1],\n",
    "    'classifier__subsample': [0.9],\n",
    "    'classifier__colsample_bytree': [0.9],\n",
    "    'classifier__min_child_weight': [7],  # INCREASED from [5]\n",
    "    'classifier__gamma': [0.6, 0.7],  # INCREASED from [0.5, 0.6]\n",
    "    'classifier__reg_alpha': [0.0, 0.1],  # NEW: L1 regularization\n",
    "    'classifier__reg_lambda': [0, 1.0],  # NEW: L2 regularization\n",
    "    'classifier__scale_pos_weight': [8]\n",
    "}\n",
    "\n",
    "print(f\"Hyperparameter search space:\")\n",
    "print(f\"  \u2022 n_estimators: {param_grid_xgb['classifier__n_estimators']}\")\n",
    "print(f\"  \u2022 max_depth: {param_grid_xgb['classifier__max_depth']}\")\n",
    "print(f\"  \u2022 learning_rate: {param_grid_xgb['classifier__learning_rate']}\")\n",
    "print(f\"  \u2022 subsample: {param_grid_xgb['classifier__subsample']}\")\n",
    "print(f\"  \u2022 colsample_bytree: {param_grid_xgb['classifier__colsample_bytree']}\")\n",
    "print(f\"  \u2022 min_child_weight: {param_grid_xgb['classifier__min_child_weight']}\")\n",
    "print(f\"  \u2022 gamma: {param_grid_xgb['classifier__gamma']}\")\n",
    "print(f\"  \u2022 reg_alpha (L1): {param_grid_xgb['classifier__reg_alpha']}\")\n",
    "print(f\"  \u2022 reg_lambda (L2): {param_grid_xgb['classifier__reg_lambda']}\")\n",
    "print(f\"  \u2022 scale_pos_weight: {param_grid_xgb['classifier__scale_pos_weight']}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"NOTE: Updated hyperparameters to reduce overfitting (12.8% train-val gap)\")\n",
    "print(\"      Iteration analysis showed optimal stopping at ~92 iterations\")\n",
    "print(\"      See analysis/bias_variance/ANALYSIS_SUMMARY.md for details\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create base pipeline\n",
    "xgb_base_pipeline = Pipeline([\n",
    "    ('preprocessor', tree_preprocessor),\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        #scale_pos_weight=scale_pos_weight,  # Keep class imbalance handling\n",
    "        random_state=random_seed,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='aucpr'\n",
    "        #eval_metric='logloss'\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Create search object (Grid or Random based on search_type)\n",
    "xgb_search = create_search_object(\n",
    "    search_type=search_type,\n",
    "    estimator=xgb_base_pipeline,\n",
    "    param_grid=param_grid_xgb,\n",
    "    scoring='average_precision',  # PR-AUC\n",
    "    cv=cv_strategy,\n",
    "    n_iter=n_iter,  # Only used for RandomizedSearchCV\n",
    "    verbose=1,  # Minimal output (CSV has all details)\n",
    "    random_state=random_seed,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit with logging\n",
    "# Using X_train_val and y_train_val gives GridSearchCV access to 80% of data (train+val)\n",
    "# instead of just 60% (train only), leading to better hyperparameter selection\n",
    "xgb_search, xgb_log_path, xgb_cv_results_path = tune_with_logging(\n",
    "    xgb_search, \n",
    "    X_train_val,  # Changed from X_train\n",
    "    y_train_val,  # Changed from y_train\n",
    "    model_name='xgboost'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "er957839e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_xgb = compare_models(\n",
    "    [\n",
    "        {'model': 'XGBoost (Baseline)', **xgb_metrics},\n",
    "        {'model': 'XGBoost (Tuned)', **xgb_tuned_metrics}\n",
    "    ],\n",
    "    verbose=False\n",
    ")\n",
    "display(comparison_xgb)\n",
    "\n",
    "print(\"\\nImprovement from tuning:\")\n",
    "for metric in ['pr_auc', 'roc_auc', 'f1', 'precision', 'recall']:\n",
    "    baseline_val = comparison_xgb.loc['XGBoost (Baseline)', metric]\n",
    "    tuned_val = comparison_xgb.loc['XGBoost (Tuned)', metric]\n",
    "    improvement = tuned_val - baseline_val\n",
    "    improvement_pct = (improvement / baseline_val) * 100\n",
    "    print(f\"  {metric.upper():12s}: {improvement:+.4f} ({improvement_pct:+.1f}%)\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cnbf0n3nntm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze XGBoost CV results for production considerations\n",
    "xgb_top_candidates = analyze_cv_results(xgb_cv_results_path, top_n=5, model_name=\"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6333960",
   "metadata": {},
   "source": [
    "### Bias-Variance Analysis\n",
    "\n",
    "Analyze the bias-variance tradeoff for tuned models to ensure they generalize well.\n",
    "\n",
    "**Key diagnostics:**\n",
    "- Train-validation gap (detects overfitting)\n",
    "- XGBoost iteration tracking (finds optimal n_estimators)\n",
    "- CV fold variance (assesses model stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53107c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias-Variance Analysis for tuned models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BIAS-VARIANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get XGBoost parameters from best estimator\n",
    "xgb_best_params = xgb_search.best_params_\n",
    "xgb_params_clean = {k.replace('classifier__', ''): v for k, v in xgb_best_params.items()}\n",
    "\n",
    "# Track XGBoost iterations to verify n_estimators\n",
    "optimal_iter, iteration_df = track_xgboost_iterations(\n",
    "    X_train_val, y_train_val,\n",
    "    X_train_val, y_train_val,  # Using same data for CV-based analysis\n",
    "    xgb_params=xgb_params_clean,\n",
    "    preprocessor=tree_preprocessor,\n",
    "    max_iterations=200,\n",
    "    cv_folds=4,\n",
    "    random_seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Analyze CV fold variance from saved results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CV FOLD VARIANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "variance_df = analyze_cv_fold_variance({\n",
    "    'Random Forest': str(rf_csv_path),\n",
    "    'XGBoost': str(xgb_csv_path)\n",
    "})\n",
    "\n",
    "print(\"\\n Bias-variance analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tfsehgfany",
   "metadata": {},
   "source": [
    "### Final Model Comparison\n",
    "Compare all baseline and tuned models to select the best performer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i4llbosecyb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison table using compare_models utility\n",
    "all_models_comparison = compare_models(\n",
    "    [\n",
    "        {'model': 'Logistic Regression', **logistic_metrics},\n",
    "        {'model': 'Random Forest (Baseline)', **rf_metrics},\n",
    "        {'model': 'Random Forest (Tuned)', **rf_tuned_metrics},\n",
    "        {'model': 'XGBoost (Baseline)', **xgb_metrics},\n",
    "        {'model': 'XGBoost (Tuned)', **xgb_tuned_metrics}\n",
    "    ],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON - Validation Set\")\n",
    "print(\"=\"*100)\n",
    "display(all_models_comparison.style.format({\n",
    "    'roc_auc': '{:.4f}',\n",
    "    'pr_auc': '{:.4f}',\n",
    "    'f1': '{:.4f}',\n",
    "    'precision': '{:.4f}',\n",
    "    'recall': '{:.4f}',\n",
    "    'accuracy': '{:.4f}'\n",
    "}).background_gradient(cmap='RdYlGn', subset=['roc_auc', 'pr_auc', 'f1', 'precision', 'recall']))\n",
    "\n",
    "# Identify best model for each metric\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"Best Performing Model by Metric:\")\n",
    "print(\"=\"*100)\n",
    "for metric in ['roc_auc', 'pr_auc', 'f1', 'precision', 'recall']:\n",
    "    best_model = all_models_comparison[metric].idxmax()\n",
    "    best_value = all_models_comparison[metric].max()\n",
    "    print(f\"  {metric.upper():15s}: {best_model:30s} ({best_value:.4f})\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Select best overall model based on PR-AUC (our optimization metric)\n",
    "best_model_name = all_models_comparison['pr_auc'].idxmax()\n",
    "best_model_prauc = all_models_comparison['pr_auc'].max()\n",
    "print(f\"\\nBEST MODEL (by PR-AUC): {best_model_name}\")\n",
    "print(f\"   PR-AUC: {best_model_prauc:.4f}\")\n",
    "print(\"=\"*100)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4iv7wqpxub",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comprehensive model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: PR-AUC comparison (our primary metric)\n",
    "ax = axes[0, 0]\n",
    "all_models_comparison['pr_auc'].plot(kind='barh', ax=ax, color='coral')\n",
    "ax.set_title('PR-AUC Comparison (Primary Metric)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('PR-AUC Score', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "# Add value labels\n",
    "for i, v in enumerate(all_models_comparison['pr_auc']):\n",
    "    ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "# Plot 2: F1 Score comparison\n",
    "ax = axes[0, 1]\n",
    "all_models_comparison['f1'].plot(kind='barh', ax=ax, color='lightgreen')\n",
    "ax.set_title('F1 Score Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('F1 Score', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "# Add value labels\n",
    "for i, v in enumerate(all_models_comparison['f1']):\n",
    "    ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "# Plot 3: Precision comparison\n",
    "ax = axes[1, 0]\n",
    "all_models_comparison['precision'].plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_title('Precision Comparison (Minimize False Positives)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Precision', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "# Add value labels\n",
    "for i, v in enumerate(all_models_comparison['precision']):\n",
    "    ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "# Plot 4: Recall comparison\n",
    "ax = axes[1, 1]\n",
    "all_models_comparison['recall'].plot(kind='barh', ax=ax, color='gold')\n",
    "ax.set_title('Recall Comparison (Catch More Fraud)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Recall', fontsize=12)\n",
    "ax.set_ylabel('Model', fontsize=12)\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "# Add value labels\n",
    "for i, v in enumerate(all_models_comparison['recall']):\n",
    "    ax.text(v + 0.01, i, f'{v:.4f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\u2713 Model comparison visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ill5y05rmz",
   "metadata": {},
   "source": [
    "### Key Insights from Hyperparameter Tuning\n",
    "\n",
    "**Random Forest (Tuned):**\n",
    "- **PR-AUC**: 0.8583 (+1.5% vs baseline) - modest improvement with focused parameter range\n",
    "- **Precision-Recall Trade-off**: Sacrificed 4.4% precision to gain 7.3% recall\n",
    "  - Precision: 94.19% \u2192 90.02% (still excellent, low FP rate)\n",
    "  - Recall: 71.13% \u2192 76.34% (better fraud detection)\n",
    "- **Optimal Parameters**: n_estimators=500, max_depth=30, min_samples_leaf=2\n",
    "  - Larger, deeper trees with minimal leaf constraints\n",
    "  - `balanced_subsample` outperformed standard `balanced` weighting\n",
    "- **Stability**: Excellent consistency across CV folds (std < 0.005)\n",
    "- **Use Case**: Best for applications prioritizing very low false positive rates\n",
    "\n",
    "**XGBoost (Tuned):**\n",
    "- **PR-AUC**: 0.8679 (+2.6% vs baseline) - **BEST PERFORMER** \ud83c\udfc6\n",
    "- **Major Precision Improvement**: Successfully rebalanced precision-recall trade-off\n",
    "  - Precision: 54.78% \u2192 72.33% (+32.1% improvement!)\n",
    "  - Recall: 84.05% \u2192 83.60% (maintained strong performance)\n",
    "  - F1: 0.6633 \u2192 0.7756 (+16.9% improvement)\n",
    "- **Key Finding**: `scale_pos_weight=8` optimal (much lower than class ratio of 44.3)\n",
    "  - Tuning this parameter was crucial to improving precision\n",
    "  - Changing `eval_metric` to 'aucpr' aligned training with PR-AUC optimization\n",
    "- **Optimal Parameters**: n_estimators=100, max_depth=4, learning_rate=0.1, gamma=0.6\n",
    "  - Shallow trees (max_depth=4) prevent overfitting\n",
    "  - Strong regularization (gamma=0.6, min_child_weight=5) boosts precision\n",
    "  - Fewer estimators needed with optimized parameters\n",
    "- **False Positive Reduction**: 918 \u2192 423 (54% reduction in FP)\n",
    "- **Use Case**: Best overall balance for production fraud detection\n",
    "\n",
    "**Tuning Strategy Insights:**\n",
    "- GridSearchCV exhaustive search proved valuable for focused parameter ranges\n",
    "  - Random Forest: 8 combinations tested\n",
    "  - XGBoost: 108 combinations tested\n",
    "- Initial searches with RandomSearchCV can be viewed in models/logs/*.csv files\n",
    "- Making `scale_pos_weight` tunable was critical (not just using class imbalance ratio)\n",
    "- Shallow trees (depth 3-5) consistently performed better than deeper trees\n",
    "- High regularization (gamma, min_child_weight) essential for precision\n",
    "\n",
    "**Model Selection:**\n",
    "- **XGBoost (Tuned)** selected as best model by PR-AUC (0.8679)\n",
    "- Exceeds all performance targets:\n",
    "  - \u2705 PR-AUC > 0.85\n",
    "  - \u2705 ROC-AUC > 0.95 (0.9790)\n",
    "  - \u2705 F1 > 0.75 (0.7756)\n",
    "  - \u2705 Precision > 0.70 (0.7233)\n",
    "  - \u2705 Recall > 0.80 (0.8360)\n",
    "\n",
    "**Next Steps:**\n",
    "1. Evaluate XGBoost (Tuned) on held-out test set\n",
    "2. Analyze feature importance to understand fraud detection drivers\n",
    "3. Consider threshold optimization for custom precision-recall trade-offs\n",
    "4. Prepare final model for deployment with production pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939f47c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notebook 2 Complete: Model Selection & Hyperparameter Tuning\n",
    "\n",
    "**What we accomplished in this notebook:**\n",
    "1. \u2705 Loaded and prepared data (train/val/test split)\n",
    "2. \u2705 Applied feature engineering with FraudFeatureTransformer\n",
    "3. \u2705 Trained baseline models (Logistic Regression, Random Forest, XGBoost)\n",
    "4. \u2705 Performed hyperparameter tuning with GridSearchCV on train+val combined\n",
    "5. \u2705 Selected best model: **XGBoost** (PR-AUC: 0.8679+)\n",
    "\n",
    "**Best Model Selected:**\n",
    "- **Model**: XGBoost (Tuned)\n",
    "- **Validation PR-AUC**: 0.8679+ (from cross-validation)\n",
    "- **Method**: GridSearchCV with 4-fold stratified CV on train+val combined\n",
    "- **Saved Files**:\n",
    "  - `best_params.json` - Optimal hyperparameters for XGBoost and Random Forest\n",
    "  - `validation_metrics.json` - Validation performance metrics for comparison\n",
    "\n",
    "**Next Steps (Notebook 3):**\n",
    "\n",
    "The next notebook (`fd3_model_evaluation_deployment.ipynb`) will:\n",
    "1. **Load** optimal parameters from `best_params.json`\n",
    "2. **Load** validation metrics from `validation_metrics.json`\n",
    "3. **Recreate** same data splits (train/val/test)\n",
    "4. **Retrain** final model with optimal parameters on train+val combined\n",
    "5. **Evaluate** on held-out test set (completely unseen)\n",
    "6. **Analyze** feature importance\n",
    "7. **Optimize** classification threshold\n",
    "8. **Save** model artifacts for deployment\n",
    "\n",
    "**Important**: The test set has NOT been used yet - it remains completely held-out for unbiased final evaluation in Notebook 3.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d964b6c3",
   "metadata": {},
   "source": [
    "## Save Best Parameters & Metrics\n",
    "\n",
    "Save the optimal hyperparameters and validation metrics for use in Notebook 3.\n",
    "\n",
    "**Files to be saved:**\n",
    "1. `best_params.json` - Best hyperparameters for Random Forest and XGBoost from GridSearchCV\n",
    "2. `validation_metrics.json` - Validation set performance metrics for comparison with test set\n",
    "\n",
    "**These files will be loaded in Notebook 3** to:\n",
    "- Train the final production model with optimal parameters\n",
    "- Compare test set performance against validation performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712719f0-9d7a-44b0-a723-0642910c2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best hyperparameters and validation metrics for Notebook 3\n",
    "best_params = {  \n",
    "    'random_forest': rf_search.best_params_,  \n",
    "    'xgboost': xgb_search.best_params_\n",
    "}\n",
    "# Save hyperparameters\n",
    "with open('best_params.json', 'w') as f:\n",
    "    json.dump(best_params, f, indent=2)\n",
    "\n",
    "# Save validation metrics for comparison in Notebook 3\n",
    "validation_metrics = {\n",
    "    'xgboost_tuned': {\n",
    "        'roc_auc': float(xgb_tuned_metrics['roc_auc']),\n",
    "        'pr_auc': float(xgb_tuned_metrics['pr_auc']),\n",
    "        'f1': float(xgb_tuned_metrics['f1']),\n",
    "        'precision': float(xgb_tuned_metrics['precision']),\n",
    "        'recall': float(xgb_tuned_metrics['recall']),\n",
    "        'accuracy': float(xgb_tuned_metrics['accuracy'])\n",
    "    },\n",
    "    'cv_best_score': float(xgb_search.best_score_),\n",
    "    'note': 'Validation performance from model trained on train set only (for comparison with test set)'\n",
    "}\n",
    "with open('validation_metrics.json', 'w') as f:\n",
    "    json.dump(validation_metrics, f, indent=2)\n",
    "\n",
    "print(\"\u2713 Saved best parameters to best_params.json\")\n",
    "print(\"\u2713 Saved validation metrics to validation_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868186e6-92d0-48a1-8de1-5c97bd63254f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}